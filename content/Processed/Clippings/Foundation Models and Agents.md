---
title: "Foundation Models and Agents"
source: "https://www.gene.com/stories/foundation-models-and-agents"
published:
created: 2025-12-15
description: "Featuring Aviv Regev, Head of gRED, Genentech, and Jure Leskovec, Professor of Computer Science, Stanford University."
tags:
  - "clippings"
---
## Featuring Aviv Regev, Head of gRED, Genentech, and Jure Leskovec, Professor of Computer Science, Stanford University.

Dec 9, 2025

In our season six finale, we dive deeper into how artificial intelligence (AI) is shaping the future of drug discovery and scientific research. With remarkable scale and speed, AI models parse through complex datasets and confirm or generate hypotheses, which can help scientists accelerate R&D. In this episode, co-host Danielle Mandikian welcomes Aviv Regev, Head of gRED, and Jure Leskovec, Professor of Computer Science at Stanford University, to talk about foundation models and autonomous agents. Together, they explore the opportunities and challenges of applying AI in drug discovery, including balancing innovation with scientific rigor and the evolving role of scientists. They also discuss how AI is reshaping the future of research — from building more biologically meaningful models to advancing agent-based systems and lab automation.

*If you would prefer to read a transcript of this episode, please click [here](https://www.gene.com/stories/#transcript)*.

### SUBSCRIBE BELOW TO CATCH EACH EPISODE

[![](https://www.gene.com/assets/frontend/img/subscribe-itunes.png)](https://itunes.apple.com/us/podcast/two-scientists-walk-into-a-bar/id1163432306?mt=2) [![](https://www.gene.com/assets/frontend/img/subscribe-spotify.png)](https://open.spotify.com/show/4EcnTbqEgeFb4EeUkv1wsy?si=-4uU9yeaTQaQR0w39Y9IxA) [![](https://www.gene.com/assets/frontend/img/subscribe-rss.png)](http://feeds.soundcloud.com/users/soundcloud:users:256626891/sounds.rss) [![](https://www.gene.com/assets/frontend/img/subscribe-youtube.png)](https://music.youtube.com/watch?v=TO5IkmBqgRg&list=PLS5dut9m5mUBXjdebuK7V4KhRUGItITkv)

*If you want to learn more about the groundbreaking science happening in our labs, . To learn more about the jobs in our research and early development group, [click here](https://www.gene.com/careers/find-a-job?searchterms=gRed&utm_source=SN&utm_medium=P&utm_term=12990&utm_content=Podcast&utm_campaign=SN2SWIB).*

---

**Transcript of Two Scientists Walk Into A Bar: “Foundation Models and Agents” with Aviv Regev and Jure Leskovec**

***Maria**: I’m Maria Wilson.*

***Danielle**: And I’m Danielle Mandikian.*

***Maria**: And we are scientists. We. Love. Science.*

***Danielle**: Yeah, we do. So, when we aren’t doing it, the next best thing is to talk about science! And what’s really awesome is we’re surrounded by some of the most brilliant minds in research!*

***Maria**: We are going to step away from the labs today to talk to other scientists about the cool stuff they are thinking about, working on and imagining...*

***Danielle**:... as well as how some of these discoveries just might lead to new medicines. So, grab your favorite drink, get ready to unlock your science brain and join us for Two Scientists Walk into a Bar…*

***Maria**: The show for scientists, science geeks, and the people who love them!*

---

***Danielle**: Do you know what an AI agent is, and can you define it?*

***Employee responses:***

*Can I define an AI agent? It's like the guy who's like running things in the background, right?*

*It's often a kind of, like, LLM core, which exists in an environment where it has some amount of memory and access your tools that it can use to execute tasks.*

*An AI agent? No, not me. \[Laughs\]*

*I think it's for help or troubleshooting, or like customer support, maybe?*

*I think an AI agent helps aggregate all of the information that is out there and summarize it to the question that you're asking so that you, yourself, do not have to go individually search the different sources.*

---

**Danielle**: Hi everyone, welcome to the show! I'm Danielle Mandikian, and believe it or not, we're already on the final episode of the season. And what we're gonna do is round up our discussions about unmet need with our old friend, artificial intelligence. Last season, we got the opportunity to talk to a lot of scientists about how AI is utilized in their research. And if you haven't checked out those episodes yet, queue it up! But today what we're gonna do is take a deeper dive into foundation models and the emergence of autonomous agents. And what we'll do is we'll talk about the capabilities of these tools, how they're actually accelerating discovery in both academia and industry, and then we'll also talk about what this really means for the future of scientific research. So, to explore this, I'm really excited to welcome back computational biologist and AI expert Aviv Regev. Welcome!

**Aviv**: Thank you for having me.

**Danielle**: And making history on the pod, we have our first ever external guest. So I would like to welcome to the bar a computer science professor from Stanford University, Jure Leskovec. Welcome.

**Jure**: Yeah. Thank you for having me.

**Danielle**: All right, so can one of y'all explain to me what is a foundation model? And are there different types?

**Jure**: So it's a large neural network model that has been pretrained on a lot of data, and generally, it's been pretrained in what is called a self-supervised way, right? So an example of this would be large language models are trained over long pieces of text or long pieces of computer code, and they're essentially predicting the next word, or they are predicting the next character or the next token, right? And the exciting thing is as you pretrain these large models this way, they basically are able to kind of learn that domain and as you make these models bigger, they're starting to get capabilities that you did not put directly into the model. So now on the biology side, we also see the emergence of these large, let's say pretrained models. You can think of them at several different, let’s say, scales of resolution. You can think of molecular foundation models – basically you get a sequence of amino acids of the protein, they will give you a representation, a very compact representation of the – of that protein. And then, you know, now on top of that, you can build folding models, you can do a lot of different things – but now you have a representation of that molecule. Then you have foundation models at the single-cell level that are trained now on a lot of single-cell RNA seq data to give in our compact representation of the cell. And then you could also start thinking about foundation models for spatial data or for tissues – so collections of cells.

**Danielle**: What makes these tools so powerful in our research?

**Aviv**: So, what makes them powerful in the research is kind of at multiple levels. The first one is, you have to think about how people used to use models. Say you're a biologist. You do an experiment, you collect some data, and you in fact train your model on the data you collected, and you ask it questions that you kind of predefine to yourself. Usually, you would train it actually in the context of that question and within the context of the data that you collected. And that's it. And when you're done with that, you're kind of gonna let it go. It is quite likely no one will use that model again. It was just a representation of the data that you already collected, and you asked it a relatively narrow question. And the question that you predefined is the one based on which you actually build the model. In the foundation model world, you kind of turn everything a different way. So first of all, it's not just the data you collected – it's a lot of data from a lot of places across many, many, many different contexts, many of which you can't even decide for yourself whether they're even relevant or not. But it turns out when you show, during training, when the model gets retrained on this much broader variety of things, it picks up much more essential pieces of understanding and information kind of about the world. So if it is, for example, a model over cells, in the traditional world – I don't know – I am interested in the gut, in a disease like inflammatory bowel disease, or IBD. So, I'm going to take a dataset, I'm going to collect a dataset of cells from patients with IBD, I'm going to do some analysis on them and ask them IBD questions. And you might think that's the best thing I can do because I'm only looking at IBD. But it turns out that you understand better the language of cells as a model if you go to see, first of all, many other things that happen in the gut. It's not just IBD. There's healthy people. There's patients with celiac disease. There is colorectal cancer. It's not just your colon, it could also be your small intestine and your esophagus. It turns out, it's even better if you also let it see cells from the skin and from the lung and from the kidney and from the brain, and maybe also from many, many other organisms throughout evolution. You learn the language of cells better, and now you can give better answers – both about IBD and about plenty of other things. And in fact, we're not limited. It turns out maybe whatever's happening in IBD is also important when you have a lung disease or a skin disorder or colorectal cancer. So it gives you this broader context, which is something we usually appreciate in a scientist. We say, “Wow, this scientist knows so much.” It's because they were exposed to a lot of different things. They draw all these connections – similar thing for the model.

**Danielle**: Can you help me understand what are some of the limitations or challenges that we face currently with building these models?

**Jure**: Yes. So, I think there is a lot, right? It is a super fast-moving field, and we are learning a lot as we go. I think right now we do not, for example, understand too well what is the best data to use, how much data we need, how this data needs to be, in many times, collected, sampled, and so on, right? And I would say similarly, like even if you think about large language models, we kind of train them on the entire internet just because it's there, right? And that is already great, but in the post-training phases, we kind of collect special datasets that allow, kind of – that give models special abilities, like writing code, doing mathematical reasoning, and so on. So I think if – now in, let's say, in biology, we follow that trajectory, I think we need to invent what are these post-training phases, and what kind of data we need to collect and what kind of tasks we need post training that will really give these models new abilities. I think another challenge is that, you know, biology is a discovery-based science – so it's not about repeating the same thing over and over again, but it's kind of discovering and generalizing to something new. And once it's been discovered, we don't need to go there anymore, we want to go somewhere else. And I think that's fundamentally harder than, you know, asking ChatGPT when Napoleon was born or something. Like it's something we already know, and it's just kind of recalling. So I think this kind of notion of generalizing to somewhere else where you were not trained, right? You were trained on one type of data, but really the questions we want to ask is about the area where there is no data, because they don't know that yet, right? So, understanding that generalizability and developing the technology that allows us to generalize well and kind of predict well the things that haven't yet happened or that we just don't know yet, I think is the key benefit of these models, and giving them that ability, I think, is also a big open question. How much of that we can do? Where can we do it? How can we do it? Under what conditions, and so on.

**Aviv**: And on the data side, we don't even know whether the kind of style of data we have, its capacity, what has already been done – is that a lot or a little? We don't really know. We don't know if we had a hundred times or a thousand times more, would that be transformative and actually change what can happen with models, or in fact it's going to be totally the same? It's like that's what's – what there is. I think there's a belief that more will be better, but we don't really know because we kind of have to learn the rules of the game as we play it. But I think there's two things that are especially important in science. One is that in science, we also have, for certain areas, some fundamental understanding of the laws or constraints of the phenomenon. So for example, if you work with molecules, there's principles from physics and from chemistry that we actually understand. Is it actually beneficial to introduce these constraints and kind of let the model only operate in a world that's, like, physically and chemically legitimate? Or is it better to just show it a lot of physics and chemistry, it will learn it all on its own and learn the right thing? That's an open question. We don't know the answer to it. However, it's kind of an empirical question. You can try and see how things perform. Similarly, when you're in biology – so molecules really matter to us a lot because we try to make great molecules. We want the model actually to generate these new general things, these new things that the model didn't see because those – that could be the next medicine, for example. Similarly, when you try to understand biology – like find what might be the gene that causes disease – then you need causality. It's not enough that there is a description of what we already know. You want the model somehow to be able to tell you like what if – to answer “what if” questions. If I did this, would that be beneficial? Or, what might be the reason or the cause that I'm observing this phenomenon? And for that, again, you need the model either to be interpretable in those terms, or actually to be built originally within the framework where this is baked in. And historically again, the first generations of these models, this was not part of them. And we don't know whether this would actually make them better, or it's something that we should just let them, kind of, see a lot and, somehow, they figure it all out and we just come after the fact and get the explanation to it. But these are super important for biology, for chemistry, for the impact of AI on science and on medicine.

---

***Wellington**: Hi Danielle!*

***Danielle**: Hey, Wellington. Hey, Karen, welcome back! Did you miss us?*

***Karen**: I really missed you guys. Although, I was at a bar in Italy, as you mentioned, and enjoying my Aperol Spritz when the last episode dropped.*

***Wellington**: So jealous. \[Laughs\]*

***Karen**: \[Laughs\] But it's great to be back. Jure and Aviv were mentioning that it's a really big challenge to not know the right amount or type of data to train these models. So what gives us the confidence to trust the answers that we get from these models?*

***Danielle**: You know, I don't know that we have a set answer for that. I think it's a very iterative process and that's kind of why people are always talking about needing to keep scientists in the loop to kind of keep evaluating the progress and then keep refining as the model needs to evolve.*

***Wellington**: So to follow up on Karen's question, when you're talking about iterations, is this the scientific way of saying you're double checking your work?*

***Danielle**: Yeah, triple check. So something that we always do as scientists is this idea of cross-validation, and that's where we take expected results or truths that we know that we can count on and cross-check it against the predictions that we would get out of a given system.*

---

**Danielle**: One of the things that y'all had brought up that I think is also very interesting is, you know, when you were talking about these foundational models and the prediction, it's kind of like this kind of figuring out what's the next part in a sequence, like linearly or spatially or whatever. But then, you also talked about building the models so that they could be thinking about the hypothesis or the reason. So is there another component about reasoning or logic that is the next phase of these types of foundational models?

**Jure**: So I think yes. Like, I agree with that. But basically, I think right now, maybe where we started was like we have these special biological entities, we have molecules, we have cells and so on, so we need to build representations for them. And these representations need to be enriched with all the knowledge of biology we have. And now, as Aviv was nicely saying, now that, if you have this enriched presentation, you actually need less data to build an accurate model on top of it than to directly build the model on the raw data, right? So if you say, okay, I have some gut cells, it's actually beneficial to push them through the foundation model, get a kind of biologically meaningful, enriched representation and then analyze that, than to analyze the raw data. Because the raw data is so high dimensional, so noisy, it's very hard to see stuff there to build models, tests on that. So you want to push that through the foundation model, it – the noise gets taken away, biology gets added in, you have now this small, compact representation on which you can run analysis much more reliably, right? So that, I think, is the first step in this foundation model.

**Aviv**: Again, for a listener who might be a scientist but not a computer scientist, this is actually what the scientist's brain does a lot. You show them something, it's kind of messy, it's kind of unclear, but they can see inside it already. And that is because, in fact, their brain was trained with a lot of prior scientific knowledge, so they know to pay attention to these things, and they know that these things are less material, and they know, let’s say, these genes and their expression, they mean something already, or these chemical groups in a small molecule mean something already. That's actually part of what our brains do. They do a lot of other things, but they do that. And they do that on the foundation of a lot of knowledge that they were already exposed to. So the foundation model is that. It's kind of this exposure to a lot of preexisting data, information, knowledge – whatever you would want to call it – so that when you bring another piece of information through, you don't start from scratch. It's not like, you know, if a kid who's like, I don't know, 10 or 13 years old and never yet studied something, and you show them something, they won't see the same thing as if you showed it to the same individual 10 years later after they just got through a lot of information. That's the –

**Jure**: To a trained brain, in a sense.

**Aviv**: That's the trained brain. So that is actually what Jure is describing. He's describing it for the computer scientists. But we actually have a lived experience of that as human beings. That's actually what happens to us. It's not the only thing. Our brains can do a lot of other super cool stuff that foundation models cannot yet do, but this piece – what the foundation model has an edge over, say, any of us as humans – is that they just digested a huge amount of stuff. And any human in their lifetime can only digest a certain amount of stuff. So that's a distinction. Back to you because that was just level one. \[Laughs\]

**Jure**: Exactly. Thank you for translating that. I think it's great. So now that we kind of understand these entities, now we want to do – we want to go kind of a level up and do this kind of human-level reasoning, right? And that's what the large language models who have read the entire internet, have read all the biological papers, are now able to do, right? They're able to reason over these representations, over these entities that we can encode with foundation models at a high level of obstruction that gets us then more towards this kind of, can we have now a virtual scientist? Can we talk to this, let's call it agent or whatever, that is then responding back to me, informed by my data, as well as informed by all the biological papers that can be found on the internet.

**Danielle**: I've heard the term agents before, but I don't really understand it. What is it?

**Jure**: Yeah. So what we think of an agent it's an autonomous system that is able to take actions, let’s say in the real world, get feedback from those actions, reason about those, and informed by that experience, take new actions. So if you want to have an agent, an agent has to be able to take actions. That's the key, right? Like software by itself that just outputs something on the screen, that's not enough. It has to do more. It has to be able to make connections, execute something, move something, push something. That's what an agent is. It's something that should – that is autonomous and it's able to make an action autonomously, get some result out of that actioning, and then plan what the next action should be.

**Danielle**: Aviv, could you give us an example of what utilizing an agent would actually mean with these foundation models, especially in the context of drug discovery or drug development?

**Aviv**: So I'll try. So let's start with the computational side, and then I'll turn to the actual physical, three-dimensional world, because agents can operate in that world in principle as well.

**Danielle**: Okay.

**Aviv**: So today, for example, or until recently, if you had, say, a dataset came in, okay, you wanted to analyze it and draw some scientific understanding from it. Say it came from – we started with inflammatory bowel disease – I'll just stick with it. You got some dataset from inflammatory bowel disease patients, and you wanted to analyze it and understand something about what is going on in them. Maybe they were treated with a medicine. Maybe you're just trying to figure out targets, new genes that you would want to go after, and so on. And so, you would usually have a computational biologist, a person who’s trained in application of computational methods to biological things, and they would apply a whole world of tools to this – those tools were previously developed and they analyze data – and you took the dataset and you ran this thing and you looked at the result and you're like, eh, not exactly. I don't exactly understand what's going on there. I'm going to try a little differently like this, and then I might move to this tool, and then I might move to that tool, and I will do this and I will do that. Now I'm gonna go read some papers because I need to understand what I'm seeing there. Okay, I read the papers, I have some thoughts, I'm gonna do – that's what the human does, right?

**Danielle**: Mm-hmm.

**Aviv**: Same idea. Replace the word human with autonomous agent, and it's very similar. You take an agent, which is, of course, appropriately coded and trained, et cetera. And it has the following abilities. First of all, it's equipped with a large language model itself, so you can talk to it, like we talk to, you know, you talk to ChatGPT. So you tell it: “Here's a dataset in IBD, I want you to analyze it for me.” That might be actually all you will tell it. Maybe you will say more, maybe that's all you will say. Like you hand it, you know, to your friend who sits next to you. And what can they do? They can actually run – the agent can run all of these analysis tools, the same tools, and can go to the literature because it has an LLM of the literature, so it can kind of read and think – “think,” in quotes, something along those lines. And you often would do something similar with the agent to what you do when you train a person. You actually show them some loose templates of how you work. And now what would the agent be able to do? They're able to receive your typed in instruction or spoken instruction. Then they have access to all these tools. They have the ability to launch the tool. They have the ability to receive back the results from the tool. And they can look at it – “look,” in quotes – and reason over it in their way of reasoning. And they have memory – they remember that before that, they did this step, and before that, they did that step, all of those steps, right? So they have context and memory. And they just go and do these things. They run this and they look at that and they do this and that. You can stop them, and they can also stop on their own and say, "Here's what I have for you. Like it?" And you can say, "Yeah, I do," or "I don't” – you know? – in the same way that you interact with other scientists essentially, and they become a sidekick for you. So that is in the virtual world because all this agent did is run code and look at results. But in fact, you can couple that thing to instruments. If the instruments are automatable, you can also, in principle, allow your agent to go and spin off an experiment. If it can be automated, you can spin off an experiment. And the agent can go and say, okay, now maybe it's in chemistry, now not in IBD in biology, I want the synthesis to happen. I have some automated system for synthesis, and I want the molecules back, and I'm gonna ship them off to that robot to measure their properties and then tell me what the proper – tell me what the measurements were, and I'll decide on the next step. That can also be an agent.

**Danielle**: What about you, Jure? Any examples?

**Jure**: So the question is kind of – it’s a simple question to define. So you want someone to help you design experiments, right? So you have a cell, maybe you have some tumor cells, and you're like saying, okay, what gene should I perturb for these cells to die or to express a given phenotype, right? So you have 20,000 things you can choose from and select – perturbing each one separately in the lab is too expensive, takes too long and all that. So what you would like to do is maybe you would like to select 64 or 32 or, you know, some –

**Danielle**: Something manageable. \[Laughs\]

**Jure**: – round – some round number for a computer scientist. And then you would try those, see what happens, and then you'd like to suggest the next batch and try it out and keep going like that, right? So, we built an agent, where basically you come in and say, okay, I have this type of cells, this is the phenotype I would like to express, suggest to me what genes should I perturb. Okay? And then you can go in the lab, around them, you go back and you say, okay, I did these genes, these are the results, and it will suggest the next set of experiments. Okay? So when we were developing this, it just didn't work. It was so terrible. I cannot tell you how terrible it was.

**Danielle**: I'm convinced that's good luck though. \[Laughs\]

**Jure**: Right? That's right. So then my student Yusuf had a brilliant idea – he went back to the LLM and he said: “Look, these are the genes that are the ground truth to perturb the cell type to get the phenotype you want. So what question should I ask you to give me this set of genes?" And you know what the thing responded? The thing said: "This is like you asking me to generate a random set of English words." And we were like, what is going on?

**Danielle**: How is it that funny? \[Laughs\]

**Jure**: So, we go into the original dataset, and what we found out is that the gene dictionary was off by one. So basically, all the genes were random. That's why it didn't work!

**Danielle**: Oh my gosh.

**Jure**: And now, show me a human who can look at a set of 54 letter number codes and say, oh yeah, these are random, they have nothing in common. Versus, oh yeah, these all belong to this pathway, I know it all. There is no such human. But the LLM has that knowledge. It said, look, sorry, this is a totally random set. We went back, we checked the data – it was off by one, so everything was garbled. We corrected it, and it started working beautifully.

**Danielle**: I love it.

**Jure**: Right, so it's just like, wow. Right? So that's one concrete example. And the beautiful thing is you can also ask it “Why? What's the reasoning behind it?” – point you to papers. You can really kind of work with it as a companion to design these experiments. And it works amazingly well. Better than current technologies that kind of run – learn out of the data because the current – this kind of bayesian optimization methods they are called – they learn from scratch. But the LLMs have read the “entire internet”-worth of biology papers, so they come in with all this prior knowledge that helps early on, and then, actually, they learn from the experimental results to suggest other later stages. So they both have a tremendous amount of background knowledge, as well as are able to take in kind of the evidence to suggest the next step.

**Aviv**: This requires, actually, two kinds of changes from the side that does the experiments. First of all, there is a human change. The humans have to change the way they think about – right? – now they have an agent. How do you use it? How do you sync with it? How do you engage with it? And it's really important because all of us, in some way or another, grew up in the world of calculator access. Meaning we actually believe that when you ask a computational device a question, you get a correct answer, right? You put in the thing in the calculator – you don't actually double check that it made a correct calculation. But the AI world is not like that. In one way, it is way richer, right? It read the literature, it did this, it did that. But it's not necessarily right. It's a lot more similar to a human. When you work with another person and you ask a really difficult calculation question, you're not gonna be certain that they're giving you a right answer. But they are going to be way more interesting than a calculator. So that's one big shift. The other is, experiments have to change.

**Danielle**: What do you mean by that?

**Aviv**: So when you do an experiment in a world like that, you might not want to design your experiments anymore the same way. For example, you might actually do a whole slew of experiments that are not for any particular question just because you think they make the foundation model better. Or, instead of, when you do screens – which are the kinds of experiments that Jure actually described their screens – historically, the goal was to do as big of a screen as possible up front. And why is that? Because – first of all, it's painful to do them. You know that better than I do.

**Danielle**: \[Laughs\] Yeah.

**Aviv**: But also, because then you will have all the results. You will read through all of them, and you will figure things out. But it's a fallacy because you actually can never get all the results in biology. You could always have given a different condition to the cell. And, yeah, maybe you don't count every gene at once – you can do all of them, but you can't do all their combinations. These are things that you can never do all of them. But if I can work with an agent, maybe I can do the best set of experiments overall if I let it kind of see things gradually – I'll do a batch, let it think for a moment. Come back, do another batch. Come back, do another batch. And I have to stay out of the way for a while, because if I intervene too much, I might actually kind of break the magic.

**Danielle**: Yeah.

**Aviv**: So that's one other thing that is a big shift in how you might think about experimental biology. And once you start thinking like that, you might want different styles of experiments being done and then invent some new lab techniques to make it possible, or the right kind of instrument to make it possible. It changes the calculation for the wet lab – not just for the people who do computational work.

---

***Karen**: Danielle, Jure’s example of the really cheeky agent response about that garbled data was hilarious, and it stood out as a perfect example of how agents can solve problems that a human might miss. So where else do you think using agents might be helpful in the lab?*

***Danielle**: I mean, we're not there yet, but I would absolutely love it if I could get a cheeky flag down whenever I mishandle samples, you know? Or, I like – you know, I'm still like a wet bench scientist, meaning, like, I'm in the trenches digging through cells, pulling stuff out from a biochemistry perspective, and, like, analyzing it across like 40 million different machines. It'd be phenomenal if I can have someone step in and be like, uh-uh girl, you mislabeled that. That's not even what makes sense to analyze at this point. That would save me a lot of tears. \[Laughs\]*

---

**Danielle**: Alright – representing wet lab scientists everywhere – whenever we hear this amazing capabilities of utilizing foundation models and agents to really speed up the prediction of what's a good target? How are we going to bind it efficiently? You know, sometimes that leaves some of us standing around being like, shoot, what are we supposed to do? Because historically, that's been us in the trenches, really kind of going through at this really slow pace of trial and error trying to find this out. So what does this look like in the future in terms of how foundation models and agents can actually interplay with scientists like me?

**Aviv**: So let me start by reducing the fear, and I'll start with a real example of an agent that was trained to do something known as spatial analysis for a spatial transcriptomics, okay? That is a pretty involved set of these steps and so on. There's a set of templates – people have done it before, but every time you need to do it, you do it from scratch. So we built an agent like that, but we also competed it against humans – I believe about 10 different people. Basically, we gave them the same tasks, and you can – on tasks that you can measure how accurate you are, how performant you are, and so on. And it turns out that, yes, an agent can be better than some of the humans. But it's not better than the best human. But what is especially important is that when you give the agent to a human, the human exceeds themselves and the agent, which means this is actually a tool that empowers you as a lab scientist or as a computational biologist or as a computational chemist, et cetera, et cetera. Because it lets you, first of all, take a lot of drudgery out of your work. Yeah, the first time you run spatial transcriptomics analysis, it's super interesting. The hundredth time, it's like, oh my god I have to do this again. Right?

**Danielle**: Yeah. \[Laughs\]

**Aviv**: But there's no replacement. Well, it turns out, you can figure it out when it's interesting, figuring out how to do something like that. But then, you have something that takes a lot of the drudgery out, and once in a while would show you something you wouldn't think about while you have a chance to think your own thoughts and kind of work with them together. Which, in fact, we love working with other humans for that reason. We exchange ideas. They do it like this, we do things like that, something better comes out. That is actually the world with agents. It's not a world without the scientists, it's a world where the scientist becomes a lot more empowered. It's like everyone all of a sudden has a whole bunch of interns working with them –

**Danielle**: Right.

**Aviv**: – rather than working alone. And it's amazing to have interns around. And of course, every intern is much more powered, because every intern now has an army of high school students working with them. You can kind of continue that analogy –

**Danielle**: Yeah, yeah, yeah.

**Aviv**: – as far as you want to go.

**Danielle**: But that's a great way to look at it, because then you have this kind of broader picture and you give the intern the guidance – like start this, let me know if you find anything interesting.

**Aviv**: Yeah.

**Jure**: And what is very interesting is you can always come back and ask it why? So you can kind of talk to it so it can explain why did it do what it done, why does it think this is a good next step and so on. So I think it is a really good kind of collaborator and brainstormer as well as, you know, kind of the robot that can automate certain mundane tasks that we as humans perhaps don't want to be doing. And I think that's very, as Aviv said, it's like very liberating because each one of us is expert in one area, but we are kind of not experts in other areas. And now if we have this kind of generalist agent, they can kind of supplement you or complement you in some sense in these areas where you are not the ultimate expert, right? And that kind of speeds up the scientific progress by a lot.

**Danielle**: How is this impacting science, research and development, especially from the perspective of industry versus academia?

**Jure**: I can quickly give maybe two vignettes here. So, we've developed this kind of agent that helps lab scientists accomplish their tasks. And the beautiful thing about this agent is that it has access to, let's say, 100 different, you know, ontologies and datasets and about 150 different kind of advanced bioinformatics tools that it can use to get its tasks done. And just two quick examples. So, one success was a wet lab at Stanford. They were trying to design a new cloning protocol, and amazingly, they kind of put in all the data into the agent and said, okay, this is what I want to do, give me that plasmid map \[Laughs\]. You know, I'm zero expert on this, right? But in the end, they got this cloning protocol of about, you know, at what temperature to put the cells into what kind of oven, for how long. I was just amazed. You know, I know nothing about it – so, what that cloning protocol was? And they tried it out, and it worked. And they said, look, it would take a super senior postdoc several days, weeks to come up with this. Now it took 10 minutes. Another example was a multiomics lab at Stanford School of Medicine who had continuous glucose monitoring data, physical activity data, as well as food intake data. And they just dropped, I don’t know, 500 different Excel spreadsheet files of activity of these different subjects and said, generate some good hypotheses out of this. And, you know, the thing would analyze the data and come up with a hypothesis how, I know, some temperature arises after consuming food or something like that, right? And the scientist in the lab was like, look, it would take me probably two weeks of work, two hours a day, three hours a day – and this thing did it in half an hour. So we see a lot of, I would say, enablement at this day-to-day level. Where we are going with this is actually to close the loop and say, can these systems automatically verify hypothesis and come up with experiments that try to falsify a hypothesis? And if hypothesis is not falsified, then can they come up with the next experiment and the next experiment, and this way, really try to discover knowledge. And if you think about this, this would be super amazing because we have these huge amounts of data that we as humans just don't have time to look through. And of course, we can kind of correlate everything with everything, but then we get millions of hypotheses and we don't know which ones are promising or not. So now if you could use some kind of agent that would prescreen, pre-pretest some of the hypotheses and come back and say, look, here are the ones that look interesting that I couldn't falsify, so likely they are true – you humans may want to look at this. That would be a huge enabler in, you know, the way we do science and how quickly the science progresses.

**Aviv**: It's always useful to remember how much of that process is filled with failure, right? In our industry, 90 percent of programs fail, either preclinically or clinically. That's horrible. Imagine we would make it better. Imagine we just moved from 10 percent success to 20 percent success or to 30 percent. That means, like, twice as many or three times as many benefits to humanity. That's a big deal.

**Danielle**: I always feel like I tell people that science is kind of like a bad gambling addiction. \[Laughs\] You know what I mean?

**Aviv**: \[Laughs\] Totally. But we want to change that, right?

**Danielle**: Yeah.

**Aviv**: The most critical step you actually have is deciding which targets you're gonna go after. Because if you go after the wrong target, you're gonna spend years doing many things at huge human effort, human ingenuity, time – at some point, you might go into patients. And if in the end that does not succeed, it's all because you chose the wrong target. So that's the first choice you make, but it's one that takes a long time sometimes to figure out. The other thing is that because each step is so complex – because there's so much reading and thinking and figuring out and so on – you often do it like in a sequential, in streaming mode. You try one, and if it doesn't work out, then you go and you try another one. And if that doesn't work out, you go and you try another one. What these tools allow us to do, what AI allows us to do more generally and agents allow us to do, and especially when they're coupled in a lab and we iterate – what we call the lab in a loop – when you do that, then you can actually look at a ton of things in parallel. Again, just like what Jure described. And yet, many, many of them are gonna fail. But you failed them fast, you failed them right away. You're not gonna waste all your time and effort on them. You're gonna focus your effort on where it's actually productive. That could be transformative for what we try to do for patients. Because without it, you're kind of doomed to always toiling one by one, one by one, through something that's enormous – that's, like, it feels unbounded, and it's pretty close to that. Then yeah, I mean, once in a while, we definitely are very, very lucky. But we'd rather be a lot more lucky than that. We don’t want it to feel like a gambling addiction. \[Laughs\]

**Danielle**: \[Laughs\] Yeah. Let's go 10 years into the future. You know, I've been hanging out with my favorite agent. We got through some cohorts. You know, it told me that my choices were probably not the best, sent me in the right direction. I went to bed, woke up to some results. My AI watch was like, hey, I've got the molecule, it's safe, whatever. Where do we go from there? Like how does this keep growing?

**Aviv**: I'll start by actually trying to imagine the physical world. I think especially for lab scientists, as you are one, labs haven't really changed in many, many decades. Actually, probably 100 years. The instruments changed dramatically in what they can do, but the lab environment didn't really. I'm not sure that would not – would remain true 10 years into the future. For example, it is very reasonable to assume there will be self-driving labs, like you have a self-driving car. Because, yes, in fact, that thing came to your watch. But it came from a lab that ran 24-7, and humans were busy with the long tail of creativity and the next really unimaginable thing. But the thing churned and churned and churned, and it constantly is connected together. And the lab might also have humanoid robots that have, you know, dexterity with things that look like human hands, so they can actually operate side by side. So that physical world is actually gonna get, you know, very embedded and embodied together with AI, and that has not yet happened as much to lab environments, but it's part of where the future is likely headed. Who knows? You know, it's hard to – not to, you know, prophesy, was given to the fools.

**Danielle**: No, I believe you though. I believe you.

**Aviv**: But still, that, I think, is an exciting side of it. The second part of it is I do think we will – in some ways, the scientific method will remain the scientific method, and in some ways, we might actually change the way that we think in science. And to me, that is the most exciting thing. And if you're a new person starting – if you're now an undergrad, or in your PhD or in your postdoc – that is what's gonna make your life, like, so fun. Because, you know, you still have a super flexible brain, and it's gonna shift a lot. So, the way people will do their science and think about their science might be quite different than the way that it is today. I’m not sure exactly in what way, but I think we will become much more adept at working at the true scale of science, which in chemistry – especially for drug discovery and in biology – is an enormous scale. Whereas before, we were limited, we were doomed to only work on small parts of it one at a time. Now all of a sudden, we would be able to carry because we would have our own brain and that brain next to us to carry it together.

**Jure**: Just to say, right, like basically, intelligence and reasoning are already kind of getting commoditized, right? So as time progresses, even more so. So I think that means that kind of the nature of work we do as humans is going to fundamentally change. Where I think that we are ready for the evolution – for this to really come to fruition – is the robotics, that is the next thing, right? Right now, kind of reasoning in the virtual *in silica* – that we can do quite well. But the interaction with the physical world, executing things in the physical world, is where still there is a huge gap. And maybe those gaps are actually bigger than we all think, right? But if you do things in the lab, you need to physically perform the experiment, right? So that, I think, is the next big innovation that needs to be done. Right now we basically have these agents, companions, they can reason, they are intelligent, they read the papers, they are super good as, kind of, collaborators – but I think it's the robotics piece, it's the next big thing.

**Danielle**: It's so exciting. And like, we had this episode about – Kim Homan came on and she was talking about different kinds of *in vitro* assays and using bioprinting and all this stuff, and like, none of this was even on the table like 10 years ago. I mean, it's so – I remember when liquid handlers came onto the scene, and we raced in our lab about who could do ELISAs fast – and it was like, you know, the old story with like, the steam-powered boat and stuff, and we were like living it in real time – it'd be like ah, you know? But it's all changed, now there's like whole rooms that automate certain kinds of assays. And so I do think that that's so realistic and plausible.

**Aviv**: Just like the models they're in, so does this amazing neural network known as the human brain – which is, by the way, amazingly energy efficient – learns. And as our circumstances change, the labs change, the computer science changes, AI comes about, and so on – our brains are gonna go with it, and they're gonna come up with all sorts of awesome stuff. And what's most exciting about thinking 10 years into the future is appreciating the fact there's gonna be stuff there that we're not imagining right now.

**Danielle**: This has been such a great conversation – so much fun. Thank you both for joining.

**Jure**: Yeah, thank you.

**Aviv**: Thank you.

---

***Karen**: Friends, I think this is one of my favorite episodes yet. We're going out with a bang for season six. A key take home that really stood out to me from this episode was that AI foundation models can't be – they can't do it all – and you really need the scientist working with these tools to be able to accelerate drug discovery. So my question to you, Danielle, is what is the most exciting thing you believe will come from this relationship that doesn't currently exist today?*

***Danielle**: I really think the thing that's resonated the most with me is figuring out or imagining a situation where the scientists are freed up to do bigger questions that they're interested in. Like, I'm super fascinated by how biologics actually move throughout diseased tissue and it kind of sucks for me now because I can't dive that deep into it. But if we were able to free up certain time and resources to take care of finding a target, figuring out how to drug it, then it gives us a lot more space to dig deeper into some of these other questions and feed models that can even move it faster.*

***Wellington**: Yeah, Danielle, I thought this was an incredible episode, and as you know, I've been asking, sort of, questions about data. Like, what are we going to do with all this data? And agents in this episode kind of answered that question for me. There's two things that are exciting to me. One is, as a scientist, it must be kind of exciting to think about things moving faster and getting answers to questions faster. And then I think about the translation to patients – how any improvement on how we target and discover will potentially translate to real gains from the patient side.*

***Danielle**: Yeah, and I mean, absolutely. The gains on the patient side is what this is all about. But even just from like a scientific curiosity standpoint, the other thing that's really cool is getting novel insights that we just haven't come up with yet. And having a path forward and a new way to attack something is just priceless. So what makes this episode the perfect end to a really exciting season is that you can really start to see the light at the end of the tunnel, almost like a point in time where all of the work that's come together to get these types of models and agents out there is really gonna start to produce real results. And that's what we've all been waiting for.*

***Danielle**: And that’s our show! Thanks so much for listening. If you haven't already, rate our podcast, wherever you listen – it’ll help new people find us. And make sure to subscribe. If you have any questions about the show, you can contact us at podcast@gene.com. And now for me it’s back to stalking cells!*

---

*The name **Two Scientists Walk Into A Bar** is under license and used with permission from the Fleet Science Center*