---
title: "A World of Serviceable Domains"
source: "https://www.seancai.com/philosophy/serviceable_domains"
published:
created: 2025-12-16
description: "Read my thoughts on A World of Serviceable Domains"
tags:
  - "clippings"
---
[Back to philosophy](https://www.seancai.com/philosophy)

VC has long revolved around SaaS and recurring revenue products because of its development during the formative years of web 1.0/2.0. When software's distribution cost is zero, its unit economics, compared to any other type of business, look phenomenal, and have coined hand-to-heart investor rules like SaaS's [Rule of 40](https://feld.com/archives/2015/02/rule-40-healthy-saas-company/). Services did not have a "software" type that gave it a halo, but that's changing with AI (where complex "services" can be replicated with decreasing costs with model actions, whose cost is tied to tokens and who are becoming a new class of workers).

When we made SaaS products, we were able to improve human capabilities at scale. When we replicate enterprise services in RL environments and create agents who can generalize almost as well as humans, we multiply humans at scale. Combined, our overall productivity increases as we all become managers.

![A simple illustration on how both labor and productivity changes with proper AI deployment, granted proper application of AI to tasks they are well suited for nowadays](https://www.seancai.com/images/philosophy/serviceable/AMR_Market_Map_Services_(2).png)

*A simple illustration on how both labor and productivity changes with proper AI deployment, granted proper application of AI to tasks they are well suited for nowadays*

Resulting increased labor productivity along with the potential for AI to generalize has revolutionized the unit economics of workers in three ways:

- Decreased importance of labor specialization
	- When you don't need a programmer, GTM expert, and product manager to link together to create a product, and store the expertise of all 3 into one, labor economics revolutionize
	- When everyone is a manager, strong generalists dominate
- Increased ability to generalize across business data inputs
	- Transformer models, especially in enterprise applications, mean building enterprise workflow automations for one size fits all now increasingly trumps individual workflows
	- What can be built once often lasts longer and longer in terms of usefulness, especially once one enterprise workflow is mapped out
- Rewarding agency
	- The value delta between extremely strong generalist workers and narrow specialists continues to widen; especially for specialists in white collar work being targeted by model evals
	- A large reason for the re-emergence of 996 talk in tech circles is that the marginal value of a highly versatile, skilled AI-native worker vastly outpaces the productivity of those who aren't. I wrote about this increasing ["bimodalism"](https://www.seancai.com/philosophy/bimodalism) which increasingly permeates both startups and workers

This in turn, has made services a much more productive business model:

![Source: Redpoint's ai64](https://www.seancai.com/images/philosophy/serviceable/Screenshot_2025-10-27_at_9.44.13_AM.png)

*Source: Redpoint's ai64*

The result is being seen empirically too - roles are looking more full stack than ever ([a piece from my blog](https://www.seancai.com/philosophy/founders_associated_roles), examining role titles) and FDEs, at least in name, are desired more than ever:

![FDE's postings listed more - indicating employer want for versatility given the decreasing need for labor specialization](https://www.seancai.com/images/philosophy/serviceable/Oct_7_Screenshot_from_AI_Data_Marketplace.png)

*FDE's postings listed more - indicating employer want for versatility given the decreasing need for labor specialization*

Megacaps have long been a strong proponent of services in the AI-age, as GC [points out](https://www.generalcatalyst.com/stories/the-future-of-services).

Services that were once exclusive to enterprise budgets are becoming accessible to main street - the main issue being with "scaling quality" - which is what AI is best sited for today. This, in theory, creates new markets because the marginal cost of high quality services goes down and expands the TAM of qualified buyers. In either an effort to wield their influence in AUM or take initiative to equip legacy services with AI tooling themself, a16z, Thrive, and GC have all placed incubation-type bets into companies like [Eudia](https://www.generalcatalyst.com/stories/our-investment-in-eudia).

![A16z's best practices for building out a services team is still relevant in the world of ai-enabled services](https://www.seancai.com/images/philosophy/serviceable/Reinforcement_Learning_Environments.png)

*A16z's best practices for building out a services team is still relevant in the world of ai-enabled services*

But a world where large AUM players are the only ones able to access that tailwind, if true, is quite depressing. AI-native service companies (key distinction between vertical agent companies, which aim to eventually have no human in the loop), however, are erupting in possibility.

[Absurd (YC F25)](https://tryabsurd.com/) is an ai-native ad generation consultancy which sells to top consumer AI startups which builds a bespoke orchestration layer of video/image models for video creation, and operates the tool themself as an agency. The result is sub-2 day turnaround times for videos that would require human equivalents 14+ days of labor, priced at boutique agency rates. [Genre AI](https://www.genre.ai/) is a similar a16z-backed competitor, having built the viral Kalshi ad earlier this year.

[Truvo](https://www.truvoinsure.com/) is an AI-native insurance broker that outperforms human insurance brokers by 3-5x while being registered as a human insurance broker. In domains whose information is both easily accessible by models and can be engineered to get to 99.9% end to end automation, there is no reason why "AI-native" versions of their white collar counterparts can't exist.

AI-enabled services eventually aim to productize, or make so efficient their processes that even skilled labor on their internal orchestration platforms produce SaaS-like margins.

We expect agnostic tailwinds to hasten the profitability of AI-enabled services via decreasing model costs for performance. If small models become just as performant as frontier models today, that means that inference [increasingly moves on device](https://docs.google.com/document/d/1HllKKBULFOAe8e780ISuaUbqKAR8KjRc7XTzO69MOcs/edit?tab=t.0), making AI-enabled services more accessible for smaller teams who may otherwise have been constrained by lack of access to cloud compute/inference. We can expect inference costs for even flagship models to compress and move on device - we were seeing massive inference cost decreases as early as Mary Meeker's AI report this year.

![Inference cost decreases from Mary Meeker's AI report](https://www.seancai.com/images/philosophy/serviceable/Screenshot_2025-11-02_at_9.21.53_PM.png)

*Inference cost decreases from Mary Meeker's AI report*

The TAM is naturally larger because of being able to distribute enterprise level capabilities and outcomes to consumers who otherwise would have been priced out because of substantial initial investment. In Absurd's case - this is studio-quality distribution material.

![Econ 101 Diagram of how AI & services increases TAM](https://www.seancai.com/images/philosophy/serviceable/Evolution_of_RL_Data_Cos_Page_2.png)

*Econ 101 Diagram of how AI & services increases TAM*

In practice, there are always things inherent about servicing smaller customers that don't scale with just one technology:

1. Increased Service Reps and AEs to service customers
2. Diversity of Edge Case possibilities that drive human in the loop intervention
3. Industry dynamics where large players tend to consolidate SMBs so everyone is at least mid-market sized

The pendulum shifts from distributing software products to distributing processes, contexts, and model orchestration in a world where [consumer hardware becomes performant](https://docs.google.com/document/d/1HllKKBULFOAe8e780ISuaUbqKAR8KjRc7XTzO69MOcs/edit?usp=sharing) at the same level as enterprise. In practice, aren't processes, contexts, and model orchestration also just agents on top of each other?

![Costs/Rev Uplift Matrix for AI](https://www.seancai.com/images/philosophy/serviceable/Evolution_of_RL_Data_Cos_Page_4.png)

*Costs/Rev Uplift Matrix for AI*

There are agnostic tailwinds promoting the opportunities in both B and D today in the above graph:

1. For B - model costs decreasing means the cost of reasoning within ERP and enterprise ontology decreasing - this makes the head to head comparison of model usage to RPA trivial, and more enterprise automation decisions will be done via small models
2. For D - better end to end automation coverage also means charging a premium. The individual parts of a car as a sum cost less than the assembled car, because we place a pricing premium on the thought expertise needed to assemble the pieces. The same is true for dynamically automated workflows, where model reasoning replaces a lot of the low level assembly logic that RPA fails it because of inability to generalize. **Usage-based pricing** is a common method of how companies capture that premium today:

![Usage based pricing dominates when the marginal cost of logic shifts from software licensing to inference computing (From Redpoint ai64)](https://www.seancai.com/images/philosophy/serviceable/Screenshot_2025-10-27_at_9.54.21_AM.png)

*Usage based pricing dominates when the marginal cost of logic shifts from software licensing to inference computing (From Redpoint ai64)*

## Helpful additional reading:

1. Mary Meeker's 340 page report on trends in AI ([https://www.bondcap.com/reports/tai](https://www.bondcap.com/reports/tai))
2. Redpoint ai64 ([https://www.redpoint.com/ai64/](https://www.redpoint.com/ai64/))
3. Coatue deep dive into whether we're in an AI bubble (https://drive.google.com/file/d/1Y2CLckBIjfjGClkNikvfOnZ0WyLZhkrT/view)
4. Why AI is not a bubble ([https://www.derekthompson.org/p/why-ai-is-not-a-bubble](https://www.derekthompson.org/p/why-ai-is-not-a-bubble))
5. Mechanize Blog on RL ([https://www.mechanize.work/announcing-mechanize-inc/](https://www.mechanize.work/announcing-mechanize-inc/))
6. **Vintage Data / Alexander Doria - *The Model is the product*** ([https://vintagedata.org/blog/posts/model-is-the-product](https://vintagedata.org/blog/posts/model-is-the-product))
7. **Chemistry VC – *"RL Reigns Supreme"*** ([https://www.chemistry.vc/post/rl-reigns-supreme](https://www.chemistry.vc/post/rl-reigns-supreme))
8. **Felicis – *"Rocket Fuel for AI: Why Reinforcement Learning Is Having Its Moment"*** ([https://www.felicis.com/insight/reinforcement-learning](https://www.felicis.com/insight/reinforcement-learning))
9. [Github Repo](https://github.com/datake/Papers-Of-Continual-RL) for inferring what the shape of human data for better post-training looks like in the future (continuous learning)
10. Personal list of all notable human data/RL env companies I've seen ([https://www.notion.so/RL-Envs-Dump-29545bdf028180c4ae84f3be65973d10?source=copy\_link](https://www.notion.so/RL-Envs-Dump-29545bdf028180c4ae84f3be65973d10?pvs=21))
	- [Market Map visualized](https://www.seancai.com/market) - WIP!