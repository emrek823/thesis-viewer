---
title: Toward Global Large Language Models in Medicine
authors:
- Rui Yang
- Huitao Li
- Weihao Xuan
- Heli Qi
- Xin Li
- Kunyu Yu
- Yingjian Chen
- Rongrong Wang
- Jacques Behmoaras
- Tianxi Cai
date: '2026-01-05'
categories:
- cs.CL
pdf_url: https://arxiv.org/pdf/2601.02186v1
arxiv_id: 2601.02186v1
tags:
- paper
- alphaxiv/hot
- topic/cs-CL
---

# Toward Global Large Language Models in Medicine

**Authors:** Rui Yang, Huitao Li, Weihao Xuan, Heli Qi, Xin Li...

**Date:** 2026-01-05 | **Categories:** cs.CL

[PDF](https://arxiv.org/pdf/2601.02186v1) | [AlphaXiv](https://alphaxiv.org/abs/2601.02186v1)

## Abstract

Despite continuous advances in medical technology, the global distribution of health care resources remains uneven. The development of large language models (LLMs) has transformed the landscape of medicine and holds promise for improving health care quality and expanding access to medical information globally. However, existing LLMs are primarily trained on high-resource languages, limiting their applicability in global medical scenarios. To address this gap, we constructed GlobMed, a large multilingual medical dataset, containing over 500,000 entries spanning 12 languages, including four low-resource languages. Building on this, we established GlobMed-Bench, which systematically assesses 56 state-of-the-art proprietary and open-weight LLMs across multiple multilingual medical tasks, revealing significant performance disparities across languages, particularly for low-resource languages. Additionally, we introduced GlobMed-LLMs, a suite of multilingual medical LLMs trained on GlobMed, with parameters ranging from 1.7B to 8B. GlobMed-LLMs achieved an average performance improvement of over 40% relative to baseline models, with a more than threefold increase in performance on low-resource languages. Together, these resources provide an important foundation for advancing the equitable development and application of LLMs globally, enabling broader language communities to benefit from technological advances.

## Notes

