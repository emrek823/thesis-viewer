---
source_pdf: "https://drive.google.com/file/d/16dHlKvd2pnmDzcFBDK7sGsUi3HmgAGQV/view"
drive_folder: "Portfolio/Standard Model Bio"
type: portfolio
company: Standard Model Bio
ingested: 2025-12-27
original_filename: "2025-12-26_manifesto.pdf"
---

> **Original:** [View Original PDF](https://drive.google.com/file/d/16dHlKvd2pnmDzcFBDK7sGsUi3HmgAGQV/view)

# Page 1

full

# Page 2

## Why Standard Model Biomedicine needs to exist.
In 5 years, every biomedical AI application will be leveraging a foundation model of some sort.
This model will have a ridiculously strong moat, and the reason for that moat is largely why SMB exists:

### The status quo in biomedical AI
Here's a typical example: an academic researcher has access to a reasonable amount of data via their institution, say genomics data for epilepsy. This researcher can assemble the data, train a basic model with limited compute resources and technical sophistication, but very good domain expertise. What results is a poor AI model but excellent benchmark driven by specific questions.

Researchers also realize that data drives AI performance, so they attempt to requisition data from competing academic labs or other sources. Sometimes these models get commercialized to enable data purchase, in a slow process via tech transfer offices from the home institution. By the time they get moving, the world has moved on (consider liv ai, picture health).

### The problem "why no one has done this yet"
Data is too difficult to obtain in medicine. This is an entirely artificial bottleneck, put in place for good reason: to protect patient privacy. Reasonable circumventions to this bottleneck exist: real world data companies obtain permission and deidentify patients and sell the data; academics run limited experiments on data from their institution; big pharma pays to generate data at exorbitant cost (clinical trials are at their heart data generation/collection exercises).

Here's what this evolves into::
Patients consent for their data to be used for research, sometimes unwittingly, sometimes enthusiastically. This data is then sold (hospitals) and hoarded (RWD co's, academic labs), and distribution is dramatically limited. This is not a cynical take - RWD co's add value by anonymising data, academics add nuance and domain expertise to specific findings. But it is a bottleneck.

Unlike LLM's, there is no internet scale dataset yet. As a result, it looks like biomedical AI might follow a different track than every other AI development, but it's just that biomedicine gets held back by data problems.

### The future

# Page 3

The solution is fairly obvious to us - one way or another, someone will train on all that data, and when they do, the bottleneck won't matter. Why go try to slowly access all the general data you can for your specific application when you can just get a specific subset to finetune?

That model is what we're building.

### What is it?
A multimodal foundation model for biomedical data.

### What is a multimodal foundation model for biomedical data (The Standard Model)?
An AI model that everyone uses in their AI applications for any part of clinical medicine, from drug development to standard of care application.

- The first 90% of AI models will be the same: all AI models take raw input data and produce a compressed representation that can be steered toward various use cases in the application layer.
- If you create a model that takes in any patient data and produces a representation of it, you have created a universal patient representation. Full stop. That's what we're building.

### Why this will change biomedicine:
- Application verticals are insanely skinny in biomedicine. A model that predicts melanoma outcomes is not guaranteed to predict NSCLC outcomes.
- Foundation models will fundamentally change the data landscape. Why purchase huge quantities of data when you can fine-tune with a fraction of the data in a fraction of the time for a fraction of the cost? Moreover, you'll have better performance.
- Performance will matter in biomedicine far more than general AI applications. Approvals in biomedicine typically require same or better performance, whether that's for radiology applications: Software-as-medical-device 501k clearance requires comparison to existing standard of care, which could be radiologists or current devices), drug approvals rest of slim performance gains over standard of care that mean billions of dollars of revenue. My favorite example of this is opdivo vs keytruda - both pd-1 blockades, keytruda beats SoC in 1L metastatic NSCLC monotherapy - huge market, this helps make keytruda among the best selling drugs in the world, BMS does not beat SoC. Drugs are about a similar as drugs get, Merck pays royalties to BMS for this. Minor differences in performance -> billions in revenue difference.
- When AI becomes an increasingly integrated part of the treatment process (this could go several ways, see below), big pharma will pay huge dollars for slim margins of performance just like they do with molecular assets. This will be accelerated by the fact that failure to get slim extra performance does not just decrease revenue by adjusting price. BMS literally cannot market opdivo 1L mNSCLC monotherapy at an adjusted price

# Page 4

to reflect reduced performance. Cost-revenue tradeoffs are not even legal options in many scenarios, just cost-risk tradeoffs. So if AI is at all important in efficacy, big pharma will have no choice but to pay for it: if they don't, a competitor will, and could take the whole indication.

### Why big pharma will not (or cannot) do this
When I was at BMS, I asked Greg Meyers (maybe 2021 before chatGPT) the CTO and a public advocate for AI in biopharma, to create a resource for foundation models. He asked if I meant MLOps. He was a very intelligent guy, and got it right away. While he was considering, I told him he needed to not just create a resource, but spin us out, because we were going to exhaust BMS data, and in any case, it's too biased by design (and should be): mostly BMS drugs, mostly failed drugs, mostly early drugs. Not a great dataset for creating a universal foundation model.

And in any case, the data was scattered across different departments, data access was weaponized to retain departmental clout. For example, digital pathology and genomics data lived in research/drug discovery; radiology images and trial data (including outcomes) lived in drug development. Real world data - EMR's, claims data (BMS was perhaps the largest consumer of RWD in the world), that lived in another department as well. Tooling was insanely slow for entirely bureaucratic reasons. It took 1 year to get weights and biases, a standard machine learning tool used by everyone from academic researchers to startups to openai, took a year to install, not because of price but because it took IT and Legal that long to get through the extraordinarily simple contract. For reference, this same product sold by the same BD lead at W&B took < 5 days at Adobe including contracting, negotiations, and installation. There is just no way that environments like that will produce the best AI models in the world.

What about other pharmas? As you'd expect I've spoken to everyone who would give me the time of day, including ones widely recognized by the industry as AI-forward. One person, who worked in self-driving cars w/ a hyperscaler prior to joining an ai-forward pharma, and left to do AI at another hyperscaler, called it “not just a waste of time, but a waste of life” and described internal efforts as laughable at best. The best talent, lured by the promise of rich datasets and huge resources, eventually gets frustrated and leaves.

There are extraordinarily smart people in pharma - the highest density of domain expertise in the world. But it is not an environment to build foundation models.

What about companies like Tempus, others who have a lot of data, and are publicly committing to building these models:
1) They're already looking for help, including reaching out to us, even in their areas of highest competency, and driven from CEO level or similar. One quote “you have what I want"

# Page 5

2) They're starting to hit similar bureaucratic issues as large pharma, e.g. not allowed to use Cursor - not the end of the world, but a signal.
3) Their data won't be enough
4) They can't be a small-biotech (pathos) AND build the world's best foundation model, or be a RWD/Diagnostics company AND build the world's best foundation model (tempus), they can't be an agentic pharma-ai-companion company AND build the world's best foundation model (biomni), they can't be an academic researcher AND build the world's best foundation model (Aevius).

### Why RWD companies cannot do this
It's possible but unlikely. They would have to cannibalize their RWD sales (as above, why buy RWD at scale to train AI models when you can fine-tune a foundation model). It will take an incredibly strong leader to do that. They've also already dedicated most of their organization toward sales and acquisition and analysis of RWD. Not easy to shift. There's still a role for them in providing custom validation datasets. The price of those may go up. I've had this conversation with several founders of RWD co's. They all see it coming. But founding teams of RWD co's are not, by and large, founding teams of world-leading AI co's in biomedicine.

### Do we have to compete with all of these types of companies?
No. We want to make these companies successful. They can have distribution and application layers. Those are skinny, difficult to penetrate, and have insanely long sales cycles (see weights and biases installation at BMS).

We know the best models are trained on the best data - algorithmic moats survive as a limited amount of time as trade secrets and capability. We know that data is expensive, and the RWD co's are sometimes reticent to partner. Long term, every RWD company will have to partner with a FM company, not just sell to them. RWD companies typically don't produce data, they broker it. We will partner with any data producer and offer our model in exchange for data access. Once we get a plurality, not working with us fundamentally limits their AI performance, which is unacceptable (see above).

We've partners at various stages of the "acceptance cycle”: a) we want to build the foundation model ourselves b) we want you to build it for us, and let us license it exclusively c) we know a,b won't work, but we're going to delay it as long as possible d) good, I want you to train on as much data that I can't access as possible, so that my performance is the best.

### Why academic labs cannot do this
They're data and resource limited. No academic institution can train a frontier LLM. They won't be able to train a frontier bio foundation model either.

# Page 6

Here's a typical example: an academic researcher has access to a reasonable amount of data via their institution, say genomics data for epilepsy. This researcher can assemble the data, train a basic model with limited compute resources and technical sophistication, but very good domain expertise. What results is a poor AI model but excellent benchmark driven by specific questions.

Researchers also realize that data drives AI performance, so they attempt to requisition data from competing academic labs or other sources. Sometimes these models get commercialized to enable data purchase, in a slow process via tech transfer offices from the home institution. By the time they get moving, the world has moved on (consider liv ai, picture health).

### Why other startups cannot land-and-expand and do this
Foundation models are not new product or services lines sold alongside existing features (buy our RWD or buy our foundation model, or our diagnostics test). Individual AI applications will continue to be incredibly lucrative, but they will be narrow enough that they will not justify training foundation models. If your startup predicts breast cancer outcomes, you cannot justify building a general foundation model for all cancers (let alone diseases), but you will need to rent one.

### Who will do this?
Our fundamental thesis is that only a company entirely focused on building this will be successful, because any other company will build a model that is less performant. Us.

### Will there be many who do this?
We believe there will be very few winners to supply any given disease area to start - they will be forced (because performance matters most) to choose the best data or risk regulatory approvals.

In the long term, cross-disease-area synergies will give an edge to pan-disease area models, just like in LLM's.

### Could there be winners for each disease area?
Not in the long term, because the best foundation model will be pan-therapeutic area, because many diseases are complex and span therapeutic areas. For instance, cancer treatments often require cardiac or immunology consults. There are cardiologists who only see oncology patients, likewise gastroenterologists. Cancer outcome predictions in these cases will benefit from both cardiac and oncology understanding.

# Page 7

This entirely follows LLM development - the best LLM's for legal are not trained only on legal data (though they may be fine-tuned by legal experts on legal data). The best LLM's for recipes are not trained solely on recipes, the best LLM's for shopping are not trained solely on shopping data.

### What is so special about us?
Generational talent and commitment.

We're moving insanely quickly. We released three papers last month, two months later and we're readying another three by the end of the year. Relative to large competitors we are moving fast.

Here's a few examples: Irsyad starts, and a month later he has a fantastic ICLR submission showing how to integrate protein-protein models with LLM's. In this time he also defends his PhD Thesis. The next month he builds another SoTA model, this time Lecun's latest JEPA work published a month or two ago.

Team general examples:

Erik Reinertsen - Led AI/Engineering at Prometheus, acquired by Merck for 10B largely for the biobank and tools he put together. They built a huge biobank and used it for AI driven drug development

David Laprade - two time founder, ex-stripe engineer. While at stripe led their invoices dev, in addition to generating patents. Knows how to work fast in highly regulated environments, at scale.

Zekai Chen - can produce a successful ACL submission in 1 week, including experiments and writing. Built first 3D foundation model for CT scans.

We're obsessed with humility (but not false humility), because our model will always enable downstream use cases (but be necessary for their success). Here's a recent slack channel comment that illustrates this point:
I don't actually care what my title or reporting position is in the company, I just want to meaningfully contribute to important work
8:25
so if we hire someone and at some point it becomes clear that I should report to them, that's totally fine with me
8:25
maybe that person is <X>, maybe not, I don't actually care one way or the other
8:26
(I say this in case it makes the hiring decision any easier for you)

# Page 8

We have a reasonable strategy. We've been in big pharma, we've been in academia, we've been at engineering companies, and we publish frontier AI models in biomedicine insofar as they exist.

Some of us have had big enough exits that we don't need to work, but we want to do the best work of our lives. Some of us will face immigration challenges if we fail. Some of us left places where we were building foundation models on incredible data (big pharma) because we knew it would fail long term, and we didn't want to win early just to fail later.

We have collectively been thinking about this more deeply and longer than probably anyone else on earth. The rapid release of papers today is the result of unseen growth in the last few years, starting when we were at BMS.

## Strategy

### Strategically, how do you get there?
We need: training data, capital, and validation (“help me understand, what is the model good for?”).

We get training data and capital from big partnerships. We buy some.

We get validation from academic medicine collaborators. They already have validation suites, domain expertise, international respect, validation/fine-tuning use cases, and appropriate benchmarks.

### Where do you start?
With big pharma (data and capital) and AMC's (validation and data).

### Where do you start with pharma?
We start in drug development. We do this for a number of reasons. First, AI x Bio started small - alphafold, and has been edging up from drug discovery to drug development. Drug discovery (up through preclinical) is maybe ¼ the budget of drug development, and both of those together are about the commercial budget of a big pharma.

# Page 9

Drug development follows academic standard of care very closely, because new drugs have to beat standard of care to get approved. SoC will continue to evolve via AI tools, and those AI tools are first piloted largely by academic medical center PIs. The more AI drives general care, the more AI will drive drug development.

### What matters in drug development?
Time and risk. If you're the clinical development lead on your pharma's lead asset or two, cost is not your problem. Some pharmas assess that every month you accelerate a clinical trial is worth $11M, averaged across all trials including failures. Novo Nordisk publicly estimates every day you accelerate a successful drug is worth $15M in revenue.

Risk also matters, and trial design is essential here, including simulating out trial design decisions like inclusion/exclusion criteria. The famous example here being Merck vs BMS in 1L monotherapy for mNSCLC - one key difference was PD-L1 biomarker thresholds. Merck had tighter inclusion threshold, which *may* have led to increased efficacy. (It's even possible BMS made the correct decision given what was known at the time, but we want to make that assessment better).

### Why do you need foundation models for that?
A foundation model for clinical data is a universal patient representation. Once you have that representation, you can simulate, reason about, and optimize for collections of patients. You can do monte carlo simulations on

### Where do you start in drug development?
We start with clinical trial enrollment. This is a huge problem - trials can be delayed 9-18 months because of enrollment. It takes a clinician 40 minutes to review a patient's information to assess whether they are eligible. Many, many patients are not even made aware they're candidates - some estimates as high as 9 in 10. In the future, when trials are use by AI-driven biomarkers, e.g. Pathos, recruitment will have to be just as sophisticated.

### So you're an enrollment forecasting company?
No. That would never justify building a foundation model at the scale we imagine.

### So what else is this good for in drug development?
Trial design, ai-driven biomarker design, simulating the effects of changing I/E criteria (including complex ai biomarkers), forecasting NPV of an asset as a result of the market size changes all of the above impose, assessing go/no go decisions form preclinical -> Phase 1, through Phase 3, novel ai-driven endpoints. Once you can do the above you can even design and simulate out *entire asset programs*.

# Page 10

### Where do you start with Academia
We started with oncology, because it's the biggest market, it's the most complex disease, and it's the thin-edge of the wedge for precision medicine. “As done in oncology” is a common phrase. This led us to expand to cardiology, because we started an oncology project with MD Anderson in which cardiology is relevant (cardiac adverse event prediction in early lung cancer). It also led us to immunology (immunotherapies in cancer have several immune side effects).

### "So what is the model good for in individual care and how do you know?"
That's why we work with academic medical centers - they validate the frontier of SoC and AI. When someone asks what the model can do, we point to 10s of academic medical centers, and accelerating: at the start of this year it was 1. Next year we expect it to be 100.

AMC academics are perfect beta testers - they need frontier performance for publication, they care about it clinically, they have access to amazing data including *local* benchmarks, and they have the expertise to design the most appropriate ones. Validation is a hugely expensive part of biomedical AI development and we get it low key for free.

We also get a low-regulatory-burden environment - AMC clinicians can test their own ai tools with relatively little overhead.

Long term, we don't tell academics where this is useful, they tell us.

### Technical strategy
We also knew we needed to show competence across the entire scale of human biology. So we did. We trained SoTA models on cancer genomic sequences, protein-protein networks, language-pathology models, radiology models, and longitudinal EHR models.

Now we're integrating those into a single multimodal model that we can serve to all of our collaborators (regardless of which modalities actually get used).

### What does medium-term strategy look like?
We train on a plurality of data, and then give the model to folks who give us data back, or we start cutting them out of the model licenses. If you don't contribute, you don't get access.

## FAQ

# Page 11

### What is the standard model
An AI model that everyone uses in their AI applications for any part of clinical medicine, from drug development to standard of care application.

### Ok but what is it really
It's a model that can take in any kind of input data about a patient, like genomic sequences, CT scans, electronic health records, electrocardiograms, and map it to a vector.

### Why this vector nonsense, don't LLM's spit out words?
Yes, but before they do they map all the input words into a vector, and use that vector to produce the next word.

### Will this model be text-based?
This model will *use* text - you'd be insane not to use an LLM that's already been trained on all of scientific literature.

But the fundamental space won't be text, because so much of biomedical data won't be aligned to text easily - genomic sequences, protein-protein interaction networks, drug binding characteristics and PK/PD or dosing data.

We use a JEPA style world-model, because the latent space is more implicit. I won't explain it here, but the approach is Yann Lecun's favorite right now.'

### What makes you think you can build this model?
We already did. We need to scale it and add additional modalities

### Does it work
Yes.

# Page 12

## Prognosis Performance by Oncology Indication (MSK Cohort)

### Chart Data: AUROC by Model and Overall Performance

**Oncology Indications Legend:**
*   Bladder Cancer
*   Kidney Cancer
*   Lung Cancer
*   Ovarian Cancer
*   Pancreas Cancer
*   Prostate Cancer
*   Sarcoma Cancer
*   Upper-GI Cancer
*   Uterus Cancer

**Overall AUROC Performance per Model:**

| Model                 | Overall AUROC (Elite/Strong/Good) |
| :-------------------- | :-------------------------------- |
| Logistic Regression   | 0.612 (Good)                      |
| Random Forest         | 0.638 (Good)                      |
| Gradient Boosting     | 0.643 (Good)                      |
| Qwen3-VL 4B           | 0.664 (Strong)                    |
| SMB-EHR-4B (Public Data Only) | 0.708 (Strong)                    |
| SMB-v1-1.7B (sft)     | 0.715 (Strong)                    |
| SMB-v1-1.7B (sft+jepa)| 0.727 (Strong)                    |

*Note: The chart visually represents individual AUROC scores for each cancer type under each model, but only "Overall" scores are explicitly labelled numerically for each model. The trend shows increasing performance (AUROC) from left to right, indicating the SMB-v1-1.7B (sft+jepa) model as the latest and highest performing.*

This chart goes up and to the right. The rightmost is our latest model.

### If you're starting in development why do you care about genomic data for instance?
Because AI-driven biomarkers will require it, for one.

### Are you thinking from "first principles"?
Yes, that's why we start with "in five years everyone will be leveraging foundation models in all of biomedical AI." and worked backwards.

### What about the startups that generate data?
For patient data, this is what pharma does, and what academic medical centers do. They can only generate patients at the speed of human disease.

### What about folks with a special proprietary dataset?
This is literally pharma :p And generally speaking, those are the folks who will finetune our model.

### How do you make money?
Short term - pilots and per-therapeutic area white gloved services with pharma.

# Page 13

Medium term - we supply those who are supplying pharma (in high level CEO and SVP level talks here w/ billion+ market cap companies) - “you have what I want"

Long term - we're somehow a part of every drug development decision because we're powering the AI that's in all of it. When treatment shifts from Molecule to AI + Molecule, we'll get some slice of that pie.

It's also possible that we power the system that decides which drugs to prescribe, we make money there too.

This sounds vague but I've been told by several commercial people close to Bioptimus that they are far behind us on business strategy.

### What are you not?
We're not a drug development copilot, nor do we do molecular simulation or structure. Someday we can design the Perfect Drug with 100% chance of technical and regulatory success, but before then we'll make better drug development decisions.

We are not an agentic layer - those will be swallowed by language frontier models.

We're not a workflow tool to help drug hunters do competitive intelligence or portfolio review.

We're not an LLM company - text won't be the fundamental language of bio (but it will help).

Long term we are not *any* downstream application if we can help it. We just empower them.

We're not a diagnostics or therapeutics company.