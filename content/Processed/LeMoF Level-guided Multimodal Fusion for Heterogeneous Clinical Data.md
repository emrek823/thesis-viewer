---
title: 'LeMoF: Level-guided Multimodal Fusion for Heterogeneous Clinical Data'
authors:
- Jongseok Kim
- Seongae Kang
- Jonghwan Shin
- Yuhan Lee
- Ohyun Jo
date: '2026-01-15'
categories:
- cs.LG
- cs.AI
pdf_url: https://arxiv.org/pdf/2601.10092v1
arxiv_id: 2601.10092v1
tags:
- paper
- alphaxiv/hot
- topic/cs-LG
- topic/cs-AI
---

# LeMoF: Level-guided Multimodal Fusion for Heterogeneous Clinical Data

**Authors:** Jongseok Kim, Seongae Kang, Jonghwan Shin, Yuhan Lee, Ohyun Jo

**Date:** 2026-01-15 | **Categories:** cs.LG, cs.AI

[PDF](https://arxiv.org/pdf/2601.10092v1) | [AlphaXiv](https://alphaxiv.org/abs/2601.10092v1)

## Abstract

Multimodal clinical prediction is widely used to integrate heterogeneous data such as Electronic Health Records (EHR) and biosignals. However, existing methods tend to rely on static modality integration schemes and simple fusion strategies. As a result, they fail to fully exploit modality-specific representations. In this paper, we propose Level-guided Modal Fusion (LeMoF), a novel framework that selectively integrates level-guided representations within each modality. Each level refers to a representation extracted from a different layer of the encoder. LeMoF explicitly separates and learns global modality-level predictions from level-specific discriminative representations. This design enables LeMoF to achieve a balanced performance between prediction stability and discriminative capability even in heterogeneous clinical environments. Experiments on length of stay prediction using Intensive Care Unit (ICU) data demonstrate that LeMoF consistently outperforms existing state-of-the-art multimodal fusion techniques across various encoder configurations. We also confirmed that level-wise integration is a key factor in achieving robust predictive performance across various clinical conditions.

## Notes

