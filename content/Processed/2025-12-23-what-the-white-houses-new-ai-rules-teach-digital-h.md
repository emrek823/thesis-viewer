---
url: https://www.elevarelaw.com/blog-articles/what-the-white-houses-new-ai-rules-teach-digital-health-companies-about-building-selling-buying-ai
title: "What the White House’s New AI Rules Teach Digital Health Companies About Building, Selling & Buying AI"
clipped: 2025-12-23 13:00
source: slack
slack_channel: healthcare-aiml-deskresearch
---

# What the White House’s New AI Rules Teach Digital Health Companies About Building, Selling & Buying AI

> Source: [https://www.elevarelaw.com/blog-articles/what-the-white-houses-new-ai-rules-teach-digital-health-companies-about-building-selling-buying-ai](https://www.elevarelaw.com/blog-articles/what-the-white-houses-new-ai-rules-teach-digital-health-companies-about-building-selling-buying-ai)

AI + Health Tech

April 6, 2025

# What the White House’s New AI Rules Teach Digital Health Companies About Building, Selling & Buying AI

![](https://cdn.prod.website-files.com/67cf4c0d443e86e6c50f0579/67f4229e1f183df8edf2e0f9_Elevare-25-Image-Team-Rebecca-v1.webp)

Rebecca Gwilt

[![](https://cdn.prod.website-files.com/67c215ab56d6c9606904441b/687fc9beb7a973ec92044824_icon-linkedin.svg)

Follow on LinkedIn](https://www.linkedin.com/in/rebeccagwilt/)

![](https://cdn.prod.website-files.com/67cf4c0d443e86e6c50f0579/67f50393c13413e0c4e8275c_AdobeStock_822818456-min.jpeg)

‍**“Why should *we* care what the government’s doing with AI?”**

That’s the question we often hear from healthtech operators—especially those heads-down on go-to-market or regulatory pathways for a new AI-driven tool.

The answer? **Because the U.S. government just laid out a comprehensive blueprint for responsible AI development and acquisition—and it’s full of lessons for the private sector.**

Whether you're **building AI**, **selling to hospitals or payers**, or **evaluating vendors**, the **White House’s April 2025 AI memos (M-25-21 & M-25-22)** offer a **framework likely to be recognized by federal regulators—it’s a publicly endorsed standard for ethical, scalable AI** that indicate what regulators might accept in terms of AI quality, safety, and implementation.

Let’s break it down.

# What Happened? The Quick Context

In January 2025, the Trump administration **revoked Biden’s AI executive order** and replaced it with a new one: **EO 14179**. That move was followed by two key OMB memos on April 3:

**M-25-21: "Accelerating Federal Use of AI"**

Sets internal rules for **how federal agencies govern, deploy, and monitor AI**—with a focus on innovation, risk management, and public trust.

**M-25-22: "Driving Efficient Acquisition of AI in Government"**

Lays out detailed **procurement standards**—from risk assessments and transparency to privacy protections, IP rights, and vendor accountability.

Together, they form a **playbook for building and buying AI responsibly**—and one that **private healthcare companies would be smart to borrow from, especially if they’re interested in selling into government**. In my experience, these federal standards have a trickle-down effect to states and private standards organizations, so I recommend companies would pay close attention even if they aren't involved in federal procurement.

## 5 Lessons Digital Health Companies Should Steal from M-25-22

Even though these memos are directed at federal agencies, they’re likely to become a **regulatory baseline**—a set of expectations other agencies (and eventually private sector regulators) will refer to. They’re built on **established principles for responsible AI deployment**—like transparency, fairness, and risk management—and now come with the weight of federal endorsement.

## 1. Form a Cross-Functional AI Acquisition Team

The memo requires agencies to include legal, IT, cybersecurity, privacy, clinical, and operational voices *before* issuing RFPs or purchasing AI.

**Private sector takeaway:**  
Don’t let procurement or engineering run the show in isolation. Bring in compliance, legal, clinical, and equity experts early.

## 2. Define High-Impact AI Use Cases Upfront

Agencies must identify whether a system is “**high-impact**”—i.e., it influences rights, healthcare access, safety, or critical infrastructure.

**Private sector takeaway:**  
If your AI affects care decisions, diagnosis, patient triage, or payer approvals, treat it as “high-impact”—and build in appropriate risk management.

## 3. Bake in Portability & IP Rights to Avoid Vendor Lock-In

The guidance pushes agencies to negotiate **data portability, model interoperability, and clear IP terms**—so they don’t get stuck with closed systems.

**Private sector takeaway:**  
Whether you're buying or selling AI, address this now. Can the model be retrained with your data? Do you own outputs? Can you switch vendors without starting from scratch?

## 4. Use Performance-Based Contracts

Agencies are told to use **metrics-based contracting** and real-world testing pre- and post-purchase.

**Private sector takeaway:**  
If you're selling AI, expect scrutiny on performance claims. If you're buying, demand transparency: How is the model validated? How will success be measured over time?

## 5. Plan for Sunset or Replacement of Underperforming AI

The memos urge agencies to create **sunset criteria**—triggers for when to retire or replace underperforming tools.

**Private sector takeaway:**  
Don’t let your AI tools run indefinitely on autopilot. Set clear thresholds for decommissioning, retraining, or escalation if the tech stops performing safely or fairly.

## How M-25-21 Shapes Internal Governance

While M-25-22 focuses on procurement, M-25-21 handles the **inside game**: how agencies govern AI use from the inside out.

It requires:

* Appointing **Chief AI Officers (CAIOs)**
* Standing up **AI governance boards**
* Maintaining **public AI inventories**
* Monitoring and remediating **high-risk tools**
* Conducting **impact assessments and ongoing audits**

**For healthtech companies, this mirrors what you’ll need to show to partners, regulators, and future investors.** If your team can’t articulate how you're managing model drift, bias, or unintended use, you’re not ready for prime time.

## Why It Matters for the Private Sector—Especially in Healthcare

You might not be a government agency—but if you’re:

* Selling AI into hospitals, payers, or public health orgs
* Building AI tools used in triage, diagnosis, or benefit decisions
* Evaluating vendors offering AI-enhanced solutions

…then this framework is your **surrogate compliance guide**.

It offers a **market-tested, regulator-aligned structure** that:

* Increases buyer confidence
* Protects patient trust
* Anticipates future regulation
* Reduces long-term vendor risk

And remember: while the **White House guidance isn’t binding on you**, the **FTC, FDA, and HHS are watching**. Borrowing from these memos **won’t just keep you compliant—it will help you build a stronger product**.

## Final Thoughts: This Is the AI Procurement Playbook Healthcare Needs

Digital health companies can’t afford to treat compliance as an afterthought. Whether you're building the next diagnostic algorithm or deploying an AI-powered intake system, **M-25-21 and M-25-22 offer a roadmap worth copying**.

If you're looking for:

* A checklist for **AI vendor evaluations**
* Contract templates with **privacy & IP protections**
* Internal governance frameworks based on the **NIST AI RMF**

We’ve got you covered.

Let’s build smarter, safer, and more trusted healthcare AI—together.

[**Contact us**](https://www.elevarelaw.com/contact) to get started.

**Stay ahead of the curve** - [subscribe to our newsletter for more updates](https://share.hsforms.com/2SVPOfezFT9qTnFDlr2CxnQscnm0).

[Back to All Blogs](/resources)

[Services](/services)[Team](/team)[Resources](/resources)[Contact](/contact)

Copyright 2025 © Elevare Law. All rights reserved.

[Legal Disclaimer](/legal-disclaimer)[Privacy Policy](/privacy)