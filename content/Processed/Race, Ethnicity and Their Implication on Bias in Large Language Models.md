---
title: Race, Ethnicity and Their Implication on Bias in Large Language Models
authors:
- Hu, S.
- Li, R.
- Gao, Y.
date: '2026-01-05'
categories:
- health-informatics
pdf_url: https://www.medrxiv.org/content/10.64898/2026.01.04.26343415v1.full.pdf
paper_id: medrxiv_10.64898_2026.01.04.26343415
source: medrxiv
tags:
- paper
- source/medrxiv
- topic/health-informatics
---

# Race, Ethnicity and Their Implication on Bias in Large Language Models

**Authors:** Hu, S., Li, R., Gao, Y.

**Date:** 2026-01-05 | **Source:** medrxiv | **Categories:** health-informatics

[PDF](https://www.medrxiv.org/content/10.64898/2026.01.04.26343415v1.full.pdf)

## Abstract

Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a re-producible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.

## Notes

