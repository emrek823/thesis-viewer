---
title: AI-Driven Acoustic Voice Biomarker-Based Hierarchical Classification of Benign
  Laryngeal Voice Disorders from Sustained Vowels
authors:
- Mohsen Annabestani
- Samira Aghadoost
- Anais Rameau
- Olivier Elemento
- Gloria Chia-Yi Chiang
date: '2025-12-31'
categories:
- cs.SD
- cs.AI
- cs.LG
pdf_url: https://arxiv.org/pdf/2512.24628v1
paper_id: 2512.24628v1
source: arxiv
tags:
- paper
- source/arxiv
- topic/cs-SD
- topic/cs-AI
- topic/cs-LG
---

# AI-Driven Acoustic Voice Biomarker-Based Hierarchical Classification of Benign Laryngeal Voice Disorders from Sustained Vowels

**Authors:** Mohsen Annabestani, Samira Aghadoost, Anais Rameau, Olivier Elemento, Gloria Chia-Yi Chiang

**Date:** 2025-12-31 | **Source:** arxiv | **Categories:** cs.SD, cs.AI, cs.LG

[PDF](https://arxiv.org/pdf/2512.24628v1)

## Abstract

Benign laryngeal voice disorders affect nearly one in five individuals and often manifest as dysphonia, while also serving as non-invasive indicators of broader physiological dysfunction. We introduce a clinically inspired hierarchical machine learning framework for automated classification of eight benign voice disorders alongside healthy controls, using acoustic features extracted from short, sustained vowel phonations. Experiments utilized 15,132 recordings from 1,261 speakers in the Saarbruecken Voice Database, covering vowels /a/, /i/, and /u/ at neutral, high, low, and gliding pitches. Mirroring clinical triage workflows, the framework operates in three sequential stages: Stage 1 performs binary screening of pathological versus non-pathological voices by integrating convolutional neural network-derived mel-spectrogram features with 21 interpretable acoustic biomarkers; Stage 2 stratifies voices into Healthy, Functional or Psychogenic, and Structural or Inflammatory groups using a cubic support vector machine; Stage 3 achieves fine-grained classification by incorporating probabilistic outputs from prior stages, improving discrimination of structural and inflammatory disorders relative to functional conditions. The proposed system consistently outperformed flat multi-class classifiers and pre-trained self-supervised models, including META HuBERT and Google HeAR, whose generic objectives are not optimized for sustained clinical phonation. By combining deep spectral representations with interpretable acoustic features, the framework enhances transparency and clinical alignment. These results highlight the potential of quantitative voice biomarkers as scalable, non-invasive tools for early screening, diagnostic triage, and longitudinal monitoring of vocal health.

## Notes

