---
url: https://nanohelix.ai/blog/ai-protein-design-guide-2025
title: "Nano Helix"
clipped: 2025-12-29 08:31
source: browser-history
---

# Nano Helix

> Source: [https://nanohelix.ai/blog/ai-protein-design-guide-2025](https://nanohelix.ai/blog/ai-protein-design-guide-2025)

Machine learning (ML) has reshaped structural biology in recent years, most famously through DeepMind's AlphaFold, and emerging platforms like **Nano Helix** now equip researchers with AI-powered tools. This 2025 guide to **AI-driven protein design** and structural biology summarizes breakthroughs from the last six months (January–June 2025) – from predicting multi-molecule complexes to designing new proteins – and highlights their real-world impact.

## Breakthrough Models for Structure and Interactions

### AlphaFold 3 and Multi-Component Complexes

In late 2024, Google DeepMind announced AlphaFold 3, a major upgrade enabling the prediction of entire biomolecular complexes – not just single proteins (2). AlphaFold 3 can jointly model proteins with DNA, RNA, small molecules (ligands), ions, and even post-translational modifications, predicting how these components fit together in 3D. This expanded scope addresses a critical need: most biological processes involve multiple interacting molecules. The new model delivered a ≥50% accuracy improvement on protein–ligand and protein–nucleic acid interactions compared to prior methods. In practical terms, AlphaFold 3 brings structural biologists closer to a "one-stop" in silico experiment, where one can input several molecular parts and obtain a predicted complex structure. DeepMind launched a free AlphaFold 3 Server for non-commercial use, democratizing access to these advanced predictions. Early studies in 2025 have demonstrated AlphaFold 3's value: for example, researchers systematically modeled hundreds of mutations in the KRAS oncogene using AlphaFold 3, revealing that most mutants cause only minor structural shifts, though certain regions (like Switch II of KRAS) show greater conformational variability relevant to cancer signaling. Such findings hint at cryptic drug-binding pockets and guide precision oncology efforts. Another preprint rigorously evaluated AlphaFold 3 on natural variants of a bacterial enzyme, H. pylori catalase (KatA). It found AF3 could reproduce wild-type vs. mutant structural differences with high fidelity in most cases, especially for conservative substitutions (3). However, accuracy dropped at very flexible or interfacial sites and when the wrong oligomerization state was assumed, highlighting that user-provided context still matters in complex predictions. Overall, AlphaFold 3's debut has extended ML's reach from single proteins to the multi-molecule assemblies that drive biology, laying groundwork for modeling entire cellular pathways (4).

### Boltz-2 – Merging Structure with Binding Affinity

A landmark development in mid-2025 is Boltz-2, an open-source "biomolecular foundation model" from MIT and Recursion that simultaneously predicts a protein's structure and how strongly a ligand (e.g. a drug) will bind to it. Announced in June 2025, Boltz-2 can co-fold a protein–ligand pair and output both the 3D complex and a binding affinity estimate in about 20 seconds on a single GPU. This unified approach tackles a longstanding bottleneck in drug discovery: evaluating binding affinity (which traditionally required slow, costly physics-based simulations or lab assays). Impressively, Boltz-2 achieved accuracy on par with gold-standard free-energy perturbation (FEP) calculations – obtaining ~0.6 correlation with experimental binding data – yet slashes computation time from 6–12 hours (at ~$100 per simulation) to seconds (mere cents in compute cost). Researchers report that Boltz-2 nearly doubles the performance of previous methods, essentially closing the gap with AlphaFold 3's accuracy for structure prediction. Its novelty lies in jointly training on protein structures and binding data, producing internal representations that "learn" how structural changes affect binding free energy. Early benchmarks show the model can discern true binders from non-binders significantly better than prior scoring functions. The real-world impact is tangible: by using Boltz-2 in its pipeline, Recursion (a biotech company) reports it has cut preclinical project timescales from 42 months to 18 months, and reduced the number of compounds needing synthesis from thousands to only a few hundred. Such results underscore how integrating ML-predicted affinity is making drug discovery more efficient. **Nano Helix already exposes Boltz-2 with a friendly user interface, letting researchers run structure predictions without setup**. Notably, Boltz-2 was released under a highly permissive MIT license, reflecting an open-science ethos aimed at broad adoption. As one team member explained, most biologists and drug developers work outside of big AI labs, so freely sharing these models empowers the wider community. Boltz-2's success hints at a new generation of AI models that go "beyond structure", predicting functional properties (binding, etc.) alongside structure – a significant trend in recent structural biology (5).

## Addressing Dynamics and Flexibility

As ML models mastered static structure prediction, a new frontier has come into focus in 2025: capturing protein dynamics and multiple conformational states. Real proteins are flexible molecular machines – they may fold into ensembles of shapes or undergo motions critical for function (e.g. enzyme open vs. closed forms). AlphaFold 2 and 3, however, largely return a single static structure, essentially a snapshot of the most favorable conformation. Over the past six months, researchers have been actively exploring ways to extend AI predictions into this dynamic realm:

### Limitations of Static Predictions

A study from May 2025 highlighted that even state-of-the-art tools like AlphaFold can struggle with proteins that have inherently flexible or disordered regions. Researchers in Brussels examined alpha-1-acid glycoprotein, a shape-shifting blood protein, and found AlphaFold2 could model the protein's rigid core well but "oversimplifies the…flexible regions," failing to capture their true range of motion. When comparing AlphaFold's single-model predictions to experimental NMR data, the flexible loops and glycosylation sites were inaccurately represented. As one scientist put it, "AlphaFold is trained on static representations…but many proteins are anything but static", cautioning that blind trust in a single AI-predicted structure may mislead, especially for proteins where movement is functionally important. This realization is steering the community toward new methodologies often dubbed "energy landscape learning" – effectively teaching models to output not one structure, but an ensemble or a spectrum of possible conformations reflective of the protein's motion energy landscape (6).

### Ensemble Prediction Methods

Several innovative approaches emerged to coax multiple conformations out of AlphaFold-like models. One notable example is AFsample2, introduced in a March 2025 Communications Biology article. AFsample2 perturbs AlphaFold2's inputs (randomly masking portions of the MSA data) to reduce bias towards a single structure, thereby sampling a diverse set of plausible structures. In tests on proteins known to adopt different states, this method successfully generated high-quality alternate conformations. In fact, AFsample2 improved the prediction of "alternate state" models in 9 of 23 test cases (OC20 dataset) without losing accuracy on the native state. For membrane transport proteins – which often have inward-open and outward-open states – AFsample2 found an alternative conformation in 11 of 16 cases, with some models achieving dramatic accuracy gains (TM-score improving from 0.58 to 0.98 in one case, essentially uncovering a fully correct alternate structure). The method increased the diversity of intermediate conformations by ~70% relative to standard AF2. In a few instances, the predicted intermediate matched a known structure of a related protein, suggesting AFsample2 was finding biologically relevant states. Tools like this represent a new class of ML techniques for ensemble prediction, addressing the one-structure limitation. Other teams have similarly tweaked AlphaFold2 through dropout ensembles, shallow alignments, or specialized protocols (e.g. AlphaFold-NMR and SPEACH\_AF) to capture alternative conformers. The results, as seen in CASP protein-folding competitions and publications, indicate that AI can be driven to explore multiple minima on the folding landscape, not just the deepest one (7).

### Toward Dynamics and Hybrid Models

There's also movement to integrate ML with physics-based simulations to handle dynamics. For instance, some next-gen models incorporate molecular dynamics (MD) data into training. Boltz-2 is one example – it included MD simulations and "physical steering" in its training pipeline to ensure its predictions remain realistic and to avoid unphysical conformations. This hybrid approach helps the model account for the natural flexibility of ligands and binding sites (e.g. Boltz-2 sometimes allows proteins to adjust shape to fit a ligand, akin to induced fit). Similarly, experimental constraints are being fused with AI: a recent method dubbed "AlphaFold3x" was reported to incorporate cross-linking mass spectrometry (XL-MS) data into AlphaFold 3 predictions, by explicitly modeling chemical cross-links as distance restraints in the network. This improves accuracy for large complexes where some structural information is available. These trends show that structural ML is evolving from a purely data-driven paradigm to an augmented paradigm, where experimental and physical insights guide the AI to model what it would otherwise miss (e.g. transient states, flexible tails, multi-chain assemblies with known contacts). In summary, capturing motion is the new challenge – and early 2025 has seen meaningful progress, with tools to generate conformational ensembles and assess where AI models might need a reality check from experiments (6).

## AI in Protein Design and Engineering

Another exciting development in the past half-year is the application of ML not just to predict existing structures, but to create new proteins with desired structures or functions. This flips the traditional script: rather than elucidating how nature's proteins look, generative AI models are used to imagine proteins that nature hasn't yet made. Structural biology and protein engineering increasingly intersect here, with ML helping scientists navigate the astronomically large design space of possible sequences. Key highlights include:

### Generative Models for Novel Proteins

Researchers are leveraging deep learning frameworks like ProteinMPNN and RFdiffusion (RoseTTAFold diffusion) to design proteins that fold in specific ways or bind to targets of interest. In June 2025, a team from Chongqing University demonstrated an AI-driven workflow for creating synthetic binding proteins (SBPs) – custom protein scaffolds that can potentially be used as therapeutics or diagnostics. Using the open-source ProteinMPNN (a sequence-design network from 2022) on known structural templates, they generated novel protein sequences optimized for stability and binding. **Nano Helix integrates RFdiffusion, ProteinMPNN and RFAntibody models, giving users an accessible interface for generative protein and antibody design tasks**. The results were striking: the AI-designed binders outperformed conventionally engineered ones in metrics like solubility, stability, and binding affinity. For instance, sequences designed on monomeric scaffold structures showed much improved solubility/stability compared to the originals, while those designed on complex (multimeric) scaffolds achieved higher calculated binding energies (indicating tighter binding). This suggests the AI can tune protein properties beyond the reach of standard methods. The group identified eight promising scaffold families (including antibody fragments like Fab and scFv, as well as alternative binders like Affilin and Repebody), each made more effective by AI-guided mutations. Such improvements – e.g. making an antibody fragment more stable or an enzyme variant more active – have direct real-world impact, potentially yielding better biologic drugs or industrial enzymes. This work underscores a larger trend: deep learning is expanding the protein design search space, allowing us to venture beyond the limited variations evolution has sampled. As the authors noted, this can lead to faster and more reliable development of protein therapeutics by finding sequences humans might never think to try (8).

### RFdiffusion2 and Functional Enzyme Creation

The Institute for Protein Design (IPD) unveiled RFdiffusion2 in April 2025, a significant upgrade to their generative diffusion model for proteins. Where earlier methods could generate novel protein structures, RFdiffusion2 goes further – it can design enzymes with tailor-made active sites given only a description of the chemical reaction to catalyze. This addresses a "holy grail" in bioengineering: creating enzymes for reactions not known in nature (such as degrading pollutants or synthesizing new drugs). RFdiffusion2 uses a diffusion-based neural network to directly scaffold a specified active site motif into a protein structure. Essentially, one provides the desired arrangement of catalytic atoms (the "theozyme"), and the AI builds a protein around it that can hold those atoms in exactly the right orientation. Unlike traditional enzyme design, which required human experts to piece together parts of known proteins, the AI explores solutions automatically – building functional proteins from scratch. The impact has been dramatic: in computational benchmarks, RFdiffusion2 solved all 41 challenging enzyme design problems in a standard test set (the Atomic Motif Enzyme benchmark), whereas the previous best method solved only 16. Even more impressively, RFdiffusion2's designs worked in the lab. The team made enzymes for 5 different chemical reactions; in each case, fewer than 100 designs needed to be tested to find a successful catalyst. This is a huge leap from earlier directed evolution workflows that might screen tens of thousands of variants. One designed zinc-dependent enzyme showed orders-of-magnitude higher activity than any previously engineered counterpart. As one researcher remarked, "RFdiffusion2 has allowed us to create enzymes in weeks that begin to rival those that evolved over billions of years". This truly highlights the real-world impact: AI is accelerating molecular engineering to timelines and performance levels once unimaginable. Beyond enzymes, similar diffusion models are being fine-tuned for antibody design (e.g. human-like antibody structures to aid biotherapeutics) and even all-atom modeling that includes small molecules or non-standard amino acids. The broad takeaway is that generative ML is now a powerful tool in the structural biologist's toolkit – not only can we predict the structures nature uses, we can invent new structures

[... truncated ...]