---
title: 'Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source
  Large Language Models'
authors:
- Rohit Kumar Salla
- Manoj Saravanan
- Shrikar Reddy Kota
date: '2025-12-30'
categories:
- cs.CL
- cs.AI
- cs.LG
pdf_url: https://arxiv.org/pdf/2512.24058v1
paper_id: 2512.24058v1
source: arxiv
tags:
- paper
- source/arxiv
- topic/cs-CL
- topic/cs-AI
- topic/cs-LG
---

# Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source Large Language Models

**Authors:** Rohit Kumar Salla, Manoj Saravanan, Shrikar Reddy Kota

**Date:** 2025-12-30 | **Source:** arxiv | **Categories:** cs.CL, cs.AI, cs.LG

[PDF](https://arxiv.org/pdf/2512.24058v1)

## Abstract

Large Language Models (LLMs) like LLaMA, Mistral, and Gemma are increasingly used in decision-critical domains such as healthcare, law, and finance, yet their reliability remains uncertain. They often make overconfident errors, degrade under input shifts, and lack clear uncertainty estimates. Existing evaluations are fragmented, addressing only isolated aspects. We introduce the Composite Reliability Score (CRS), a unified framework that integrates calibration, robustness, and uncertainty quantification into a single interpretable metric. Through experiments on ten leading open-source LLMs across five QA datasets, we assess performance under baselines, perturbations, and calibration methods. CRS delivers stable model rankings, uncovers hidden failure modes missed by single metrics, and highlights that the most dependable systems balance accuracy, robustness, and calibrated uncertainty.

## Notes

