---
title: Personalization of Large Foundation Models for Health Interventions
authors:
- Stefan Konigorski
- Johannes E. Vedder
- Babajide Alamu Owoyele
- İbrahim Özkan
date: '2026-01-07'
categories:
- cs.AI
- cs.LG
- stat.AP
pdf_url: https://arxiv.org/pdf/2601.03482v1
paper_id: 2601.03482v1
source: arxiv
tags:
- paper
- source/arxiv
- topic/cs-AI
- topic/cs-LG
- topic/stat-AP
---

# Personalization of Large Foundation Models for Health Interventions

**Authors:** Stefan Konigorski, Johannes E. Vedder, Babajide Alamu Owoyele, İbrahim Özkan

**Date:** 2026-01-07 | **Source:** arxiv | **Categories:** cs.AI, cs.LG, stat.AP

[PDF](https://arxiv.org/pdf/2601.03482v1)

## Abstract

Large foundation models (LFMs) transform healthcare AI in prevention, diagnostics, and treatment. However, whether LFMs can provide truly personalized treatment recommendations remains an open question. Recent research has revealed multiple challenges for personalization, including the fundamental generalizability paradox: models achieving high accuracy in one clinical study perform at chance level in others, demonstrating that personalization and external validity exist in tension. This exemplifies broader contradictions in AI-driven healthcare: the privacy-performance paradox, scale-specificity paradox, and the automation-empathy paradox. As another challenge, the degree of causal understanding required for personalized recommendations, as opposed to mere predictive capacities of LFMs, remains an open question. N-of-1 trials -- crossover self-experiments and the gold standard for individual causal inference in personalized medicine -- resolve these tensions by providing within-person causal evidence while preserving privacy through local experimentation. Despite their impressive capabilities, this paper argues that LFMs cannot replace N-of-1 trials. We argue that LFMs and N-of-1 trials are complementary: LFMs excel at rapid hypothesis generation from population patterns using multimodal data, while N-of-1 trials excel at causal validation for a given individual. We propose a hybrid framework that combines the strengths of both to enable personalization and navigate the identified paradoxes: LFMs generate ranked intervention candidates with uncertainty estimates, which trigger subsequent N-of-1 trials. Clarifying the boundary between prediction and causation and explicitly addressing the paradoxical tensions are essential for responsible AI integration in personalized medicine.

## Notes

