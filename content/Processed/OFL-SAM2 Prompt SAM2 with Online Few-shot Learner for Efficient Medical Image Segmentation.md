---
title: 'OFL-SAM2: Prompt SAM2 with Online Few-shot Learner for Efficient Medical Image
  Segmentation'
authors:
- Meng Lan
- Lefei Zhang
- Xiaomeng Li
date: '2025-12-31'
categories:
- cs.CV
pdf_url: https://arxiv.org/pdf/2512.24861v1
arxiv_id: 2512.24861v1
tags:
- paper
- alphaxiv/hot
- topic/cs-CV
---

# OFL-SAM2: Prompt SAM2 with Online Few-shot Learner for Efficient Medical Image Segmentation

**Authors:** Meng Lan, Lefei Zhang, Xiaomeng Li

**Date:** 2025-12-31 | **Categories:** cs.CV

[PDF](https://arxiv.org/pdf/2512.24861v1) | [AlphaXiv](https://alphaxiv.org/abs/2512.24861v1)

## Abstract

The Segment Anything Model 2 (SAM2) has demonstrated remarkable promptable visual segmentation capabilities in video data, showing potential for extension to medical image segmentation (MIS) tasks involving 3D volumes and temporally correlated 2D image sequences. However, adapting SAM2 to MIS presents several challenges, including the need for extensive annotated medical data for fine-tuning and high-quality manual prompts, which are both labor-intensive and require intervention from medical experts. To address these challenges, we introduce OFL-SAM2, a prompt-free SAM2 framework for label-efficient MIS. Our core idea is to leverage limited annotated samples to train a lightweight mapping network that captures medical knowledge and transforms generic image features into target features, thereby providing additional discriminative target representations for each frame and eliminating the need for manual prompts. Crucially, the mapping network supports online parameter update during inference, enhancing the model's generalization across test sequences. Technically, we introduce two key components: (1) an online few-shot learner that trains the mapping network to generate target features using limited data, and (2) an adaptive fusion module that dynamically integrates the target features with the memory-attention features generated by frozen SAM2, leading to accurate and robust target representation. Extensive experiments on three diverse MIS datasets demonstrate that OFL-SAM2 achieves state-of-the-art performance with limited training data.

## Notes

