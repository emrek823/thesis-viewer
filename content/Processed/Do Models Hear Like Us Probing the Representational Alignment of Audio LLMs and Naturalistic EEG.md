---
title: Do Models Hear Like Us? Probing the Representational Alignment of Audio LLMs
  and Naturalistic EEG
authors:
- Haoyun Yang
- Xin Xiao
- Jiang Zhong
- Yu Tian
- Dong Xiaohua
- Yu Mao
- Hao Wu
- Kaiwen Wei
date: '2026-01-23'
categories:
- cs.SD
- cs.AI
- eess.AS
pdf_url: https://arxiv.org/pdf/2601.16540v1
arxiv_id: 2601.16540v1
tags:
- paper
- alphaxiv/hot
- topic/cs-SD
- topic/cs-AI
- topic/eess-AS
---

# Do Models Hear Like Us? Probing the Representational Alignment of Audio LLMs and Naturalistic EEG

**Authors:** Haoyun Yang, Xin Xiao, Jiang Zhong, Yu Tian, Dong Xiaohua...

**Date:** 2026-01-23 | **Categories:** cs.SD, cs.AI, eess.AS

[PDF](https://arxiv.org/pdf/2601.16540v1) | [AlphaXiv](https://alphaxiv.org/abs/2601.16540v1)

## Abstract

Audio Large Language Models (Audio LLMs) have demonstrated strong capabilities in integrating speech perception with language understanding. However, whether their internal representations align with human neural dynamics during naturalistic listening remains largely unexplored. In this work, we systematically examine layer-wise representational alignment between 12 open-source Audio LLMs and Electroencephalogram (EEG) signals across 2 datasets. Specifically, we employ 8 similarity metrics, such as Spearman-based Representational Similarity Analysis (RSA), to characterize within-sentence representational geometry. Our analysis reveals 3 key findings: (1) we observe a rank-dependence split, in which model rankings vary substantially across different similarity metrics; (2) we identify spatio-temporal alignment patterns characterized by depth-dependent alignment peaks and a pronounced increase in RSA within the 250-500 ms time window, consistent with N400-related neural dynamics; (3) we find an affective dissociation whereby negative prosody, identified using a proposed Tri-modal Neighborhood Consistency (TNC) criterion, reduces geometric similarity while enhancing covariance-based dependence. These findings provide new neurobiological insights into the representational mechanisms of Audio LLMs.

## Notes

