---
title: 'TGC-Net: A Structure-Aware and Semantically-Aligned Framework for Text-Guided
  Medical Image Segmentation'
authors:
- Gaoren Lin
- Huangxuan Zhao
- Yuan Xiong
- Lefei Zhang
- Bo Du
- Wentao Zhu
date: '2025-12-24'
categories:
- cs.CV
- cs.AI
pdf_url: https://arxiv.org/pdf/2512.21135v1
paper_id: 2512.21135v1
source: arxiv
tags:
- paper
- source/arxiv
- topic/cs-CV
- topic/cs-AI
---

# TGC-Net: A Structure-Aware and Semantically-Aligned Framework for Text-Guided Medical Image Segmentation

**Authors:** Gaoren Lin, Huangxuan Zhao, Yuan Xiong, Lefei Zhang, Bo Du...

**Date:** 2025-12-24 | **Source:** arxiv | **Categories:** cs.CV, cs.AI

[PDF](https://arxiv.org/pdf/2512.21135v1)

## Abstract

Text-guided medical segmentation enhances segmentation accuracy by utilizing clinical reports as auxiliary information. However, existing methods typically rely on unaligned image and text encoders, which necessitate complex interaction modules for multimodal fusion. While CLIP provides a pre-aligned multimodal feature space, its direct application to medical imaging is limited by three main issues: insufficient preservation of fine-grained anatomical structures, inadequate modeling of complex clinical descriptions, and domain-specific semantic misalignment. To tackle these challenges, we propose TGC-Net, a CLIP-based framework focusing on parameter-efficient, task-specific adaptations. Specifically, it incorporates a Semantic-Structural Synergy Encoder (SSE) that augments CLIP's ViT with a CNN branch for multi-scale structural refinement, a Domain-Augmented Text Encoder (DATE) that injects large-language-model-derived medical knowledge, and a Vision-Language Calibration Module (VLCM) that refines cross-modal correspondence in a unified feature space. Experiments on five datasets across chest X-ray and thoracic CT modalities demonstrate that TGC-Net achieves state-of-the-art performance with substantially fewer trainable parameters, including notable Dice gains on challenging benchmarks.

## Notes

