---
title: 'MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification
  from Images'
authors:
- Md. Sazzadul Islam Prottasha
- Nabil Walid Rafi
date: '2025-12-29'
categories:
- cs.CV
- cs.AI
pdf_url: https://arxiv.org/pdf/2512.23304v1
arxiv_id: 2512.23304v1
tags:
- paper
- alphaxiv/hot
- topic/cs-CV
- topic/cs-AI
---

# MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification from Images

**Authors:** Md. Sazzadul Islam Prottasha, Nabil Walid Rafi

**Date:** 2025-12-29 | **Categories:** cs.CV, cs.AI

[PDF](https://arxiv.org/pdf/2512.23304v1) | [AlphaXiv](https://alphaxiv.org/abs/2512.23304v1)

## Abstract

Multimodal Large Language Models (LLMs) introduce an emerging paradigm for medical imaging by interpreting scans through the lens of extensive clinical knowledge, offering a transformative approach to disease classification. This study presents a critical comparison between two fundamentally different AI architectures: the specialized open-source agent MedGemma and the proprietary large multimodal model GPT-4 for diagnosing six different diseases. The MedGemma-4b-it model, fine-tuned using Low-Rank Adaptation (LoRA), demonstrated superior diagnostic capability by achieving a mean test accuracy of 80.37% compared to 69.58% for the untuned GPT-4. Furthermore, MedGemma exhibited notably higher sensitivity in high-stakes clinical tasks, such as cancer and pneumonia detection. Quantitative analysis via confusion matrices and classification reports provides comprehensive insights into model performance across all categories. These results emphasize that domain-specific fine-tuning is essential for minimizing hallucinations in clinical implementation, positioning MedGemma as a sophisticated tool for complex, evidence-based medical reasoning.

## Notes

