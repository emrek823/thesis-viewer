---
title: Reasoning Model Is Superior LLM-Judge, Yet Suffers from Biases
authors:
- Hui Huang
- Xuanxin Wu
- Muyun Yang
- Yuki Arase
date: '2026-01-07'
categories:
- cs.CL
pdf_url: https://arxiv.org/pdf/2601.03630v1
paper_id: 2601.03630v1
source: arxiv
tags:
- paper
- source/arxiv
- topic/cs-CL
---

# Reasoning Model Is Superior LLM-Judge, Yet Suffers from Biases

**Authors:** Hui Huang, Xuanxin Wu, Muyun Yang, Yuki Arase

**Date:** 2026-01-07 | **Source:** arxiv | **Categories:** cs.CL

[PDF](https://arxiv.org/pdf/2601.03630v1)

## Abstract

This paper presents the first systematic comparison investigating whether Large Reasoning Models (LRMs) are superior judge to non-reasoning LLMs. Our empirical analysis yields four key findings: 1) LRMs outperform non-reasoning LLMs in terms of judgment accuracy, particularly on reasoning-intensive tasks; 2) LRMs demonstrate superior instruction-following capabilities in evaluation contexts; 3) LRMs exhibit enhanced robustness against adversarial attacks targeting judgment tasks; 4) However, LRMs still exhibit strong biases in superficial quality. To improve the robustness against biases, we propose PlanJudge, an evaluation strategy that prompts the model to generate an explicit evaluation plan before execution. Despite its simplicity, our experiments demonstrate that PlanJudge significantly mitigates biases in both LRMs and standard LLMs.

## Notes

