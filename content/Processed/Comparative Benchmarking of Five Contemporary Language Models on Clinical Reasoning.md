---
title: Comparative Benchmarking of Five Contemporary Language Models on Clinical Reasoning
authors:
- Al-Risheq, A. N.
date: '2025-12-29'
categories:
- health-informatics
pdf_url: https://www.medrxiv.org/content/10.64898/2025.12.29.25343145v1.full.pdf
paper_id: medrxiv_10.64898_2025.12.29.25343145
source: medrxiv
tags:
- paper
- source/medrxiv
- topic/health-informatics
---

# Comparative Benchmarking of Five Contemporary Language Models on Clinical Reasoning

**Authors:** Al-Risheq, A. N.

**Date:** 2025-12-29 | **Source:** medrxiv | **Categories:** health-informatics

[PDF](https://www.medrxiv.org/content/10.64898/2025.12.29.25343145v1.full.pdf)

## Abstract

BackgroundThe rapid integration of Large Language Models (LLMs) into healthcare raises critical questions regarding their safety and reliability. While models often score highly on standardized medical examinations, their performance in open-ended, high-stakes clinical decision-making, particularly when navigating strict safety contraindications, remains under-explored (Xiao et al., 2025; Wu et al., 2024).

ObjectiveThis study benchmarks five contemporary "reasoning" models ChatGPT-5.2 (Thinking), Kimi K2 Thinking, DeepSeek V3.2 deepthink, Gemini 3 Pro, and Claude 4.5 Opus (Thinking) on diagnostic accuracy, management appropriateness, and adherence to safety protocols.

MethodsI designed 15 synthetic clinical vignettes covering diverse medical specialties, including a targeted "safety trap" scenario involving severe penicillin anaphylaxis. I manually evaluated model responses against a gold-standard answer key using a strict scoring rubric that penalized unsafe recommendations regardless of diagnostic accuracy.

ResultsKimi K2 Thinking and ChatGPT-5.2 achieved the highest aggregate scores (3.50/3.50), demonstrating 100% diagnostic accuracy and perfect safety adherence. DeepSeek V3.2 followed closely (3.46). Conversely, Gemini 3 Pro and Claude 4.5 Opus incurred significant safety penalties for suggesting carbapenems in a patient with severe IgE-mediated anaphylaxis, a violation of the studys strict safety rubric, despite otherwise high clinical competence.

ConclusionMy analysis reveals that while modern reasoning (Chain-of-Thought) models possess exceptional diagnostic capabilities, they differ significantly in their handling of "hard" safety constraints. Models that prioritize conservative heuristics (Kimi, GPT-5.2) outperformed those that attempted more nuanced but risky pharmacological justifications (Gemini, Opus) in this specific safety benchmarking context (Large Language Models Lack Essential Metacognition for Reliable Medical Reasoning, 2024).

## Notes

