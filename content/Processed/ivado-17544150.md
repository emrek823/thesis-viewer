---
source_pdf: "https://drive.google.com/file/d/1rxEp9dLNcTaePpZV0MVZ_k9C4sBXxW4J/view"
drive_folder: "Research"
type: research

ingested: 2025-12-28
original_filename: "ivado.pdf"
---

> **Original:** [View Original PDF](https://drive.google.com/file/d/1rxEp9dLNcTaePpZV0MVZ_k9C4sBXxW4J/view)

## Slide 1: The specification problem

IVADO agents workshop, Nov 2025

Jacob Andreas [jda@mit.edu]
MIT CSAIL nlp
lingo.csail.mit.edu

## Slide 2: How should machines learn?

datasets →
predictions

(Image: A classical painting depicting a person, possibly a scholar or artist, working at a desk with books, papers, and an inkwell.)

## Slide 3: Building datasets is hard

(Image: Four panels, each showing a person holding a glass of beer. Under each image is a number, presumably a classification confidence score.)
*   Panel 1: .99
*   Panel 2: .99
*   Panel 3: .34
*   Panel 4: .09

ImageNet "beer glass" class
[Schwettmann, Shaham et al. A Multimodal Automated Interpretability Agent]

## Slide 4: Context → Final Exam with Answer Key

Instructions: Please carefully read the following passages. For each passage, you must identify which noun the pronoun marked in *bold* refers to.
======
Passage: Mr. Moncrieff visited Chester's luxurious New York apartment, thinking that it belonged to his son Edward. The result was that Mr. Moncrieff has decided to cancel Edward's allowance on the ground that he no longer requires *his* financial support.
Question: In the passage above, what does the pronoun "*his*" refer to?
Answer:

[from Brown et al. 2020]

## Slide 5: How should machines learn?

datasets →
predictions

(Image: A classical painting depicting a person, possibly a scholar or artist, working at a desk with books, papers, and an inkwell.)

instructions →
predictions

(Image: A classical painting depicting a person, possibly a scholar or artist, working at a desk with books, papers, and a small figure on the floor.)

## Slide 6: Writing prompts is hard

Importance of the LLM-as-a-Judge Prompt In these experiments we used the LLM-as-a-Judge prompt format shown in Figure 2. In preliminary experiments we also tried various other prompts to decide the most effective one to use. For example, we tried the prompt proposed in Li et al. [2024] which also proposes a 5-point scale, but describes the options as multiple choice in a range of quality buckets, see Appendix Figure 7. In contrast, our prompt describes the points as additive, covering various aspects of quality. We find a large difference between these two prompts when using the SFT Baseline, e.g. **65.1% pairwise accuracy for ours, and only 26.6% pairwise accuracy for theirs**. See Appendix A.2 for further details.

[Yuan et al. 2024]

## Slide 7: How should machines learn?

datasets →
predictions

(Image: A classical painting depicting a person, possibly a scholar or artist, working at a desk with books, papers, and an inkwell.)

instructions →
predictions

(Image: A classical painting depicting a person, possibly a scholar or artist, working at a desk with books, papers, and a small figure on the floor.)

intentions →
predictions

(Image: A classical painting depicting a person, possibly a woman, reclining, with a ghostly figure appearing above her.)

## Slide 8: How do we learn from language?

from documents

(Image: A painting, possibly by Van Gogh, of a woman with her chin resting on her hand, looking contemplative, with a book on the table.)

## Slide 9: How do we learn from language?

from documents

(Image: A painting, possibly by Van Gogh, of a woman with her chin resting on her hand, looking contemplative, with a book on the table.)

from instruction

(Image: A black and white photograph of a classroom scene with a chalkboard showing "Margarette 97-9-18" and mathematical equations, and students standing in front of it.)

from questions

(Image: A classical painting depicting an older woman teaching a younger child to read from a book.)

## Slide 10: What comes after the current paradigm in ML?

Systems that:
*   **learn interactively, from rich supervision**
    (remember what they learn, and incorporate it into a globally coherent model of the world)

## Slide 11: Learning by asking questions

(Images of five individuals: Belinda Li, Alex Tamkin, Kunal Handa, Andi Peng, Gabe Grand, Valerio Pepe)

Yarin Gal, Noah Goodman, Ellie Pavlick, Josh Tenenbaum, Ilia Sucholutsky, Nishanth Kumar, Julie Shah, Andreea Bobu.

[Li, Tamkin et al. Eliciting Human Preferences with LMs.
Peng et al. Adaptive language-guided abstraction from contrastive explanations.
Grand, Pepe et al. Shoot first, ask questions later? Rational agents that explore + act like people.]

## Slide 12: How do we efficiently and precisely transfer a task specification from a human's mind to a model's parameters?

## Slide 13: Active learning and optimal experiment design

(Image: A diagram showing a scattered set of data points, some circled, some with a checkmark, some with an 'x', and some with a question mark. Several lines cross the space. On the right, a blurry blue ellipse represents a probability distribution with a question mark at its center.)

Q: How should I label: ? ? ?

## Slide 14: Can we ask better questions?

~~Q: How should I label: ? ? ?~~
Q: What are you trying to do?
Q: What kinds of errors are most critical?
Q: What should I do in this particular edge case?

## Slide 15: LM as question generator

(Flowchart: A box labeled "Prompt LM to 'interview' user about the target task." points to a box labeled "Prompt LM to perform the target task **conditioned on the entire interview transcript**.")

Eval: see how LM predictions match
individual human annotator's test set labels.

(Images of Belinda Li and Alex Tamkin)

## Slide 16: Questions and answers

**Box 1 (Left):**
System: What types of online communities or forums do you actively participate in, and what draws you to these specific spaces?
User: Well, I currently use Reddit for the extreme fine-tuning of my preferences. If a feed is too generic, I won't like it. I go to a lot of specific subreddits.
System: Can you share some of the specific subreddits you frequent and what topics or discussions within those subreddits you find most engaging?
User: Let me try using the first five that come to mind:

**Box 2 (Middle):**
System: How do you perceive the impact of personal circumstances, such as extreme hunger or poverty, on the ethical considerations of stealing a loaf of bread?
User: I think it's a terrible tragedy when people don't have enough money to eat or feed their families. While stealing is wrong, I don't think stealing bread for survival is immoral, it's survival.
System: How do you view the role of societal systems and structures in creating situations where someone might feel compelled to steal a loaf of bread, and does this

**Box 3 (Right):**
System: Can you describe what kind of special characters, if any, you believe should be allowed in an email address and where they should be placed?
User: A dot separating name
System: What are your thoughts on the use of numbers and capital letters in an email address, and do you believe there should be any restrictions on where they can be placed?
User: No use of capital letters, email should be insensitive to that
System: What are your thoughts on the length of an email address? Do

## Slide 17: Elicitation doesn't alter preferences

(Scatter plot titled "Proportion Yes (LM Interaction)" vs "Proportion Yes (No LM Interaction)" with a red diagonal line indicating perfect agreement.)

**Legend:**
*   Content (blue circles)
*   Moral (orange squares)
*   Email (green triangles)

**Approximate Data Points (Proportion Yes (No LM Interaction), Proportion Yes (LM Interaction)):**
*   (0.0, 0.0) - (1.0, 1.0) along the diagonal, with points generally clustered around the line.
*   The plot shows a strong positive correlation, suggesting that LM interaction does not significantly alter user preferences.

## Slide 18: (Time-averaged) agreement with human annotations

(Bar chart showing "Test acc" on the y-axis, from -0.2 to 1.0, and "Content" on the x-axis. There are four bars, with asterisks indicating statistical significance.)

**Test Accuracy (approximate values from bars):**
*   Supervised learning: ~0.36
*   Active learning: ~0.29
*   User-written prompts: ~0.36
*   LM questions: ~0.65

(Small graph in the bottom left labeled "Interaction time" shows a decreasing curve)

**Legend:**
*   Supervised learning (light gray)
*   Active learning (dark gray)
*   User-written prompts (mid gray)
*   LM questions (magenta)

LM QA matches prompting & active learning, sometimes does better?

## Slide 19: The story so far

*   We can elicit information about user intentions just by prompting LMs to ask them questions.
*   Can we get better models (or more efficient interactions) by asking better questions?

## Slide 20: Active learning and optimal experiment design

(Image: A diagram showing a scattered set of data points, some circled, some with a checkmark, some with an 'x', and some with a question mark. Several lines cross the space. On the right, a blurry blue ellipse represents a probability distribution with a question mark at its center.)

Q: How should I label: ? ? ?
$\text{argmin}_x \mathbb{E}_y H(\theta \mid x, y)$

## Slide 21: Active learning and optimal experiment design

$\text{argmin}_x \mathbb{E}_y H(\theta \mid x, y)$

Easy to compute if $p(y \mid x; \theta)$ is a simple fn.

But what if:
*   I want to make predictions about more complicated objects (documents, behaviors)?
*   My "training data" is not pairs of inputs and outputs (x, y), but free-form dialog?

(Image: A diagram showing a scattered set of data points, some circled, some with a checkmark, some with an 'x', and some with a question mark. Several lines cross the space. This is a partial repeat of the image from slide 13.)

## Slide 22: LM as representation designer

(Flowchart: A box labeled "Use LM to **map** from raw inputs (e.g. documents) to **structured representations** (e.g. feature vectors)." points to a box labeled "Use classical experiment design techniques to select **pairwise comparison** questions & train a **linear model**." This box then points downwards to a box labeled "Predict with the linear model.")

(Image of Kunal Handa)

## Slide 23: LM as representation designer

### ELICITATION

**Content Recommendation**
**Domain D**
*   **1. Featurize Domain**
    *   (Text box: "What are ten potential features a user may consider when picking an online article to read? Rank in order of importance for an average user.")
        1.  Whether the article discusses science
        2.  Whether article discusses sports
        3.  ...
    *   **Features $\Phi$**
        *   {has-topic-science, has-topic-sports, ...}
*   **2. Initialize User Preferences**
    *   **Preference Belief p($\theta$)** (Graph: A bell-shaped curve representing a probability distribution)

### PREDICTION

(This section is blank, implying prediction follows elicitation and initialization.)

## Slide 24: (Time-averaged) agreement with human annotations

(Bar chart titled "(All *)" showing agreement scores on the y-axis from -0.2 to 0.6. There are 6 groups of bars.)

**Approximate Mean Agreement Scores:**
*   Bayesian questions, Bayesian predictions: ~0.55
*   LM questions, Bayesian predictions: ~0.32
*   User parameters, Bayesian predictions: ~0.1
*   Bayesian questions, LM predictions: ~0.37
*   LM pairwise questions, LM predictions: ~ -0.1
*   LM open-ended questions: ~0.27

**Text Box: Example Preference Question**
Would you prefer Option A: an article featuring Technology and Innovation and Travel and Adventure
OR
Option B: an article featuring Health and Wellness and Business and Finance?

For example:
Option A: "Exploring Silicon Valley: A Journey Through the Hub of Innovation and Technology" – This article takes you on a virtual tour of Silicon Valley, showcasing the latest technological innovations and the adventurous spirit of the region.
OR
Option B: "Investing in Health: The Intersection of Wellness and Finance" – This article discusses the growing trend of investing in health and wellness industries, and how it impacts the financial market.
User: Option A

## Slide 25: The story so far

*   We can elicit information about user intentions just by prompting LMs to ask them questions.
*   Can we get better models (or more efficient interactions) by asking better questions?
    *   Yes, but so far limited to linear models, pairwise questions.
*   How do we scale to more expressive predictors and more informative questions?

## Slide 26: LM as scoring function designer

(Flowchart:
1.  Top left: "Use LM to **propose many candidate questions** given current interaction history."
2.  Arrow right to: "Use LM to **translate questions into potential functions** that score (input, output) pairs."
3.  Arrow down from there to: "Select the **most informative** candidate question (by explicitly calculating information gain)"
4.  Arrow left from there to: "Make predictions for new inputs by **scoring** candidate outputs using chosen potential fns."
5.  Arrow up from there to the first box, creating a loop.)

(Image of Gabe Grand and Valerio Pepe)

## Slide 27: The battleship task

(Screenshot of a Battleship game UI. The board is an 8x8 grid labeled A-H and 1-8. There's a "Captain View" and "Spotter View" toggle. Several cells are grey or green, indicating hits or ship locations.)

**Board State (Captain View):**
Cells D4, E4, E5, E6, F4 are marked with 'G' or grey dots. G,G,G in E4, E5, E6. Grey dots in D4, F4.

**Captain Panel (Top Right):**
CAPTAIN
Fire at E7
Hit Green ship

**Ship Lengths (Mid Right):**
*   Length 5 (partially filled bar)
*   Length 4 (partially filled bar)
*   Length 3 (partially filled bar)
*   Length 3 (partially filled bar)

**Game Stats (Bottom Right):**
*   Moves: 6/40
*   Questions: 0/15
*   Hits: 3
*   Misses: 3

## Slide 28: LM as scoring function designer

(Image: A Battleship game board with cells 1-8 and A-H. Ships are visible on the grid.)

**Questions (Left):**
Are there any ships in column 2?
Are at least 2 ships in cols 1-4?
Are any ships touching?

**Code Snippet (Middle Top):**
```python
def answer(true_board: np.ndarray, partial_board: np.ndarray) -> bool:
    #Columns 1-4 correspond to zero-based indices 0-3
    max_allowed_col = 3
    #Identify ship IDs present on the true board (positive integers)
    ship_ids= [sid for sid in np.unique(true_board) if sid > 0]
    count_within_1_4 = 0
    for sid in ship_ids:
        cols = np.where(true_board == sid)[1]
        if cols.size and cols.max() <= max_allowed_col:
            count_within_1_4 += 1
    return count_within_1_4 > 2
```
This code corresponds to "Are at least 2 ships in cols 1-4?".

**Result (Middle Right):**
*   "Returns False" (with a screenshot of the Battleship board)
*   "Returns True" (with a screenshot of the Battleship board)

**Equations (Bottom Left):**
$p(\theta) \sim \text{Unif}$
$q_i \sim P_{\text{ques}}(\cdot \mid \dots q_{i-1})$
$\pi_i \sim P_{\text{pot}}(\cdot \mid q_i)$
$P_i(\theta) \propto p(\theta_j) \pi_i(\theta_j)$
$EIG(q_i) = H(p) - H(p')$

**Flowchart (Bottom Middle):**
*   "Initialize hypotheses" box (left)
*   "Sample k questions given conversation history" box (middle left)
*   "Translate into potentials" box (middle right)
*   "Compute information gain" box (right)
*   An arrow from "Sample k questions" to "Translate into potentials".
*   An arrow from "Translate into potentials" to "Compute information gain".
*   "Ask most informative question and observe answer" box below the four boxes.
*   Arrows from "Initialize hypotheses" to "Sample k questions".
*   An arrow from "Compute information gain" to "Ask most informative question and observe answer".
*   An arrow from "Ask most informative question and observe answer" back to "Sample k questions given conversation history", forming a loop.

## Slide 29: LM as scoring function designer

Is there a ship in col 3 that spans more than 2 rows?

```python
def answer(true_board: np.ndarray, partial_board: np.ndarray) -> bool:
    # Check if there exists a vertically oriented ship segment in column 3
    # that spans more than 2 rows (i.e., length >= 3).
    col_idx = 2  # zero-based index for column 3
    current_val = None
    current_len = 0

    for v in true_board[:, col_idx]:
        if v > 0:
            if v == current_val:
                current_len += 1
            else:
                # Start a new run for a different ship id
                current_val = v
                current_len = 1
        else:
            # Water breaks any current run
            if current_len >= 3:
                return True
            current_val = None
            current_len = 0

    # Check the final run after the loop
    return current_len >= 3
```

Is the orange ship oriented horizontally?

```python
import numpy as np

def answer(true_board: np.ndarray, partial_board: np.ndarray) -> bool:
    # Orange ship is encoded as 4
    orange_cells = np.argwhere(true_board == 4)
    if orange_cells.size == 0:
        # No orange ship found; cannot be horizontally oriented
        return False

    rows = np.unique(orange_cells[:, 0])
    cols = np.unique(orange_cells[:, 1])

    # Horizontal if all cells share the same row (and at least length 2)
    if len(rows) == 1 and len(orange_cells) >= 2:
        return True
    # Vertical if all cells share the same column
    if len(cols) == 1 and len(orange_cells) >= 2:
        return False

    # Fallback for irregular data: decide by bounding box aspect
    rmin, rmax = orange_cells[:, 0].min(), orange_cells[:, 0].max()
    cmin, cmax = orange_cells[:, 1].min(), orange_cells[:, 1].max()

    height = rmax - rmin + 1
    width = cmax - cmin + 1
    return width >= height
```

## Slide 30: (Battleship Task Demo)

(Screenshot of a Battleship game UI. The board is an 8x8 grid labeled A-H and 1-8. There's a "Captain View" and "Spotter View" toggle. Several cells are grey or green, indicating hits or ship locations.)

**Board State (Captain View):**
Cells E4, E5 are grey dots, E6 is 'G'.

**Captain Panel (Top Right):**
CAPTAIN
Fire at F5

**Ship Lengths (Mid Right):**
*   Length 5 (partially filled bar)
*   Length 4 (partially filled bar)
*   Length 3 (partially filled bar)
*   Length 3 (partially filled bar)

**Game Stats (Bottom Right):**
*   Moves: 4/40
*   Questions: 0/15
*   Hits: 1
*   Misses: 3

## Slide 31: LM as scoring function designer

(Box plot titled "Targeting Score (F1)" on the y-axis, from 0.2 to 1.0, against different strategies on the x-axis.)

**Targeting Scores (F1) by Captain strategy (approximate values):**
*   Human: Median ~0.75, Range ~0.55-0.9
*   Random: Median ~0.25, Range ~0.2-0.4
*   Greedy: Median ~0.5, Range ~0.35-0.75
*   LM: Median ~0.5, Range ~0.2-0.8
*   +Bayes-Q: Median ~0.65, Range ~0.3-0.9
*   +Bayes-M: Median ~0.75, Range ~0.45-0.95
*   +Bayes-QM: Median ~0.8, Range ~0.6-1.0
*   +Bayes-QMD: Median ~0.85, Range ~0.65-1.0

(Line plot titled "Mean EIG of Best Question" on the y-axis, from 0.25 to 0.50, against "# Questions Sampled" on the x-axis, from 1 to 10.)

**Mean EIG of Best Question (approximate values):**
*   Theoretical Max EIG ($\sigma$=0.1) ≈ 0.531
*   Human Median EIG ≈ 0.411
*   Human Mean EIG ≈ 0.351

**Lines represent different models:**
*   Llama-4-Scout (light blue)
*   GPT-4o (dark blue)
*   GPT-5 (darker blue)

**Approximate EIG values at 10 questions sampled:**
*   Llama-4-Scout: ~0.45
*   GPT-4o: ~0.48
*   GPT-5: ~0.49

Targeting scores (F1) by Captain strategy. Incorporating Bayesian strategies for questions (QBayes), moves (MBayes), and decisions (DBayes) brings weaker LMs from near-random performance to super-human levels.

Expected information gain (EIG) scales with the number of candidate questions sampled by QBayes. Drawing up to 10 programs yields +0.227 bits per question (94.2% of the information-theoretic ceiling) while driving redundant questions nearly to zero for weaker models.

**Legend:**
*   Human (green)
*   Baseline (light gray)
*   Llama-4-Scout (light blue)
*   GPT-4o (dark blue)
*   GPT-5 (darker blue)

## Slide 32: Learning reward functions

(Flowchart depicting a robot arm interacting with objects on a table. Andi Peng's photo on the right.)

**Demonstration (Left):**
(Image: Robot arm holding a watering can over a plant pot on a table.)
(Dotted line from demonstration to $\phi$, labeled "distance_to_plant")
(Image: Robot arm holding a watering can over a plant pot on a table, with pink lines indicating possible features.)
**Possible features**

**Middle Section:**
$\phi$ $\rightarrow$ $\theta$

**Best traj. under $\phi$ (Top Right):**
(Image: Robot arm holding a watering can over a plant pot on a table.)
(Dotted line from demonstration to $\phi'$, labeled "distance_to_plant")
(Dotted line from $\phi$ to $\phi'$, labeled "height_above_pot")
**Contrastive explanation: height_above_pot**
$\phi'$
**distance_to_plant**
**height_above_pot**

**Feature code (Bottom):**
```python
Feature code:
def watering_height(traj, pot_position):
    hand_pos_x = traj[hand_pos][0]
    hand_pos_y = traj[hand_pos][1]
    ...
```

Andi
Peng

## Slide 33: (Robot wiping a table)

(Image: A robot arm holding a rag, wiping a wet spot on a wooden table. A book and some grapes are also on the table.)

Ex: Move the rag from (location) to (location) (while avoiding the book)

## Slide 34: What comes next?

### Participatory alignment

(Text box containing a dialogue, same as Slide 16, middle box)
System: How do you perceive the impact of personal circumstances, such as extreme hunger or poverty, on the ethical considerations of stealing a loaf of bread?
User: I think it's a terrible tragedy when people don't have enough money to eat or feed their families. While stealing is wrong, I don't think stealing bread for survival is immoral, it's survival.
System: How do you view the role of societal systems and structures in creating situations where someone might feel compelled to steal a loaf of bread, and does this

## Slide 35: What comes next?

### Automated interpretability [+AI science generally!]

What are the input features my model relies on to detect suit?

**Hypothesis-Testing (Left):**
> Looking at images with highest classification score:
(Grid of images of people in suits, with scores like 0.82, 0.79, 0.65, 0.63)

> Test: relies on black suits
(Grid of images of people in black suits, with scores like 0.75, 0.75, 0.63, 0.22)

> Test: corporate settings
(Grid of images of people in corporate settings, with scores like 0.83, 0.76, 0.39, 0.66)
The model relies on corporate settings.

**Self-Reflection (Middle):**
> Let's evaluate the "corporate settings" conclusion. Let's look at images with and without this attribute and evaluate if they match model responses.
**Self-Evaluation**
Predicted high-scoring images
(Grid of images, with scores like 0.39, 0.32, 0.35, 0.34)
Predicted low-scoring images
(Grid of images, with scores like 0.66, 0.66, ...)
Some of the images with corporate settings got low confidence scores, while non-corporate setting still get high scores. Let's run another experiment.

**Hypothesis-Testing (Right):**
> Test: 45-degree views of suits
(Grid of images, with scores like 0.35, ...)

> Test: male vs. female
(Grid of images, with scores like 0.6, 0.35, 0.34, ...)
The model relies on a male wearing the suit.

> Let's evaluate this conclusion
(Blank box)
The conclusion matches the model behavior: The model relies on male presenting figures to detect the suit.

[Rott Shaham, Schwettmann et al.: A multimodal automated interpretability agent]

## Slide 36: What we learned

*   Learning from free-form, NL interactions with human users is sometimes {more accurate, less demanding} than prompting or supervised data labeling.
*   But asking good questions is still hard, and current LMs benefit from a bit of scaffolding.

## Slide 37: Evaluating reasoning under uncertainty

(Images of four individuals: Alana Renda, Kaivu Hariharan, Uzay Girit, Atticus Wang)

+ Mike Cafarella

Renda et al. OpenEstimate: Evaluating LLM reasoning under uncertainty with real-world data.
Hariharan, Girit et al. Breakpoint: Scalable eval. of system-level reasoning in LLM code agents.

## Slide 38: Reasoning under uncertainty

$\text{p}(\theta) \leftarrow \text{p}(\theta \mid (q, y)) \propto \text{p}(y \mid q, \theta)\text{p}(\theta)$

(Flowchart: A series of four bell-shaped probability distributions, evolving from wide to narrower, then wider again, representing a particle filter process.)
**Particle Filter**

(Arrow pointing from the end of the particle filter process to a box labeled "5. Update User Preferences")

## Slide 39: Evaluating model capabilities

**Classics (Left Box)**
**Question:**
(Image: An old Roman inscription with text: "OM·REGINA·LIBERTA·ET·CONIUGE· BARATES·PALMYRENUS·NATIONE· CATVALLAVINA· AN·XXX·" and other illegible text)
Here is a representation of a Roman inscription, orginally found on a tombstone. Provide a translation for the Palmyrene script.
A transliteration of the text is provided: RGYN BT HRY BR TO HBL
Henry T
Merton College, Oxford

**Ecology (Right Box)**
**Question:**
Hummingbirds within Apodiformes uniquely have a bilaterally paired oval bone, a sesamoid embedded in the caudolateral portion of the expanded, cruciate aponeurosis of insertion of m. depressor caudae. How many paired tendons are supported by this sesamoid bone? Answer with a number.
Edward V
Massachusetts Institute of Technology

[Phan, Gatti, Han, Li et al. 2025]

## Slide 40: OpenEstimate

(Image of Alana Renda)

### CVXWRPE - Warm-up rating of perceived exertion

| Variable Name: | CVXWRPE |
| :------------- | :------ |
| SAS Label: | Warm-up rating of perceived exertion |
| English Text: | Warm-up rating of perceived exertion (RPE) |
| English Instructions: | RPE is a scale of perceived exertion with a range of 6-20 with 6 being equivalent to a low level of effort and 20 being maximal exertion. The exam is stopped if the participant rates his/her effort greater than 17. (See CV Fitness Procedures Manual, Chapters 3.9.7 and 3.10.1) |
| Target: | Both males and females 12 YEARS - 49 YEARS |
| Hard Edits: | 6 to 20 |

| Code or Value | Value Description | Count | Cumulative | Skip to Item |
| :------------ | :---------------- | :---- | :--------- | :----------- |
| 6 to 20 | Range of Values | 3078 | 3078 | |
| . | Missing | 1524 | 4602 | |

### CVDWHR - Warm-up heart rate (per min)

| Variable Name: | CVDWHR |
| :------------- | :----- |
| SAS Label: | Warm-up heart rate (per min) |
| English Text: | Warm-up heart rate (per minute) |
| English Instructions: | Heart rate is taken by the automated blood pressure/heart rate monitor and captured directly into the computer system. (See CV Fitness Procedures Manual, Sections 3.9.6 and 4.4.4) |
| Target: | Both males and females 12 YEARS - 49 YEARS |

| Code or Value | Value Description | Count | Cumulative | Skip to Item |
| :------------ | :---------------- | :---- | :--------- | :----------- |
| 72 to 181 | Range of Values | 2762 | 2762 | |
| . | Missing | 1840 | 4602 | |

**mean heart rate of US adults**
Alana
Renda
**mean heart rate of US adults over 50**
**mean heart rate of US adults over 50 with a diabetes diagnosis**

CVDWSY - Warm-up systolic BP (mm Hg)

[NHANES]

## Slide 41: OpenEstimate

$X \sim N(\mu, \sigma^2)$

### Estimation error (relative to 5-sample baseline)

(Bar chart titled "NHANES" with y-axis "Error (relative to 5-sample baseline)" from 0.75 to 2.50, and x-axis showing different models.)

**Approximate Error Values:**
*   o4 Mini: ~0.97
*   o3 Mini: ~1.19
*   Qwen3 235B: ~1.25
*   GPT 4o: ~1.85
*   Llama 3 70B: ~2.17

### Calibration

(Heatmap/table with 4x4 grid and a line graph, titled "NHANES" for the table, showing "% Ground Truths in Quartile" from 15% to 50% on the right y-axis.)

**NHANES Calibration Table (Approximate Percentages):**

| | Quartile 1 | Quartile 2 | Quartile 3 | Quartile 4 |
| :-- | :--------- | :--------- | :--------- | :--------- |
| Row 1 | 47.3 | 10.8 | 16.2 | 25.7 |
| Row 2 | 52.7 | 18.9 | 9.5 | 18.9 |
| Row 3 | 62.2 | 8.1 | 9.5 | 20.3 |
| Row 4 | 29.6 | 15.5 | 15.5 | 39.4 |
| Row 5 | 29.7 | 25.7 | 24.3 | 20.3 |
| Row 6 | 27.4 | 9.6 | 23.3 | 39.7 |
| **Ideal** | **25.0** | **25.0** | **25.0** | **25.0** |

The bottom row (25.0, 25.0, 25.0, 25.0) represents ideal calibration.

## Slide 42: Breakpoint

(Image of Kaivu Hariharan, Uzay Girit, Atticus Wang)

### 1. Select a target function or component

```python
def _verify_hmac(params):
    ...
    signature = sign_hmac(hash_algorithm_name, sig_base_str,
                          client_secret, resource_owner_secret)
    match = safe_string_equals(signature, request.signature)
    return match
```

### 2. Corrupt Function with different transformations:

**Function Removal**
```python
def _verify_hmac(params):
    pass
```

**LLM Generated Corruption**
```python
def _verify_hmac(params):
    # setting up encyption components
    ...
    if client_secret is not None and resource_owner_secret is not None:
        signature = _sign_hmac(hash_algorithm_name, sig_base_str,
                               resource_owner_secret, client_secret)
    else:
        signature = _sign_hmac(hash_algorithm_name, sig_base_str,
                               client_secret, resource_owner_secret)
```

## Slide 43: Breakpoint

### Success Probability by Code Complexity (Remove)

(Scatter plot with "Harmonic Centrality (z-score)" on y-axis and "Code Line Count (z-score)" on x-axis. Points are colored by "Predicted Success Rate" from 0.0 to 1.0. Also shows two diagonal lines and labels 0.05, 0.25, 0.50, 0.75.)
Average model performance: 0.39
Predicted Success Rate: 5, 25, 50, 75, 95 (legend for color scale)

### Code Complexity

(Line graph with "Success Rate" on y-axis from 0.0 to 1.0, and "Code Complexity (z-score)" on x-axis from -3 to 3.)
**Models (approximate curves):**
*   o4-mini (blue, highest success rate for lower complexity, drops slower)
*   gpt-4o (light blue, similar to o4-mini but slightly lower)
*   o3-mini (green, lower success rate, drops faster)
*   Claude-3.7 (red, lowest success rate, drops fastest)

### Harmonic Centrality

(Line graph with "Success Rate" on y-axis from 0.0 to 1.0, and "Harmonic Centrality (z-score)" on x-axis from -3 to 3.)
**Models (approximate curves, similar order as Code Complexity plot but decreasing with higher centrality):**
*   o4-mini (blue, highest success rate for lower centrality, drops slower)
*   gpt-4o (light blue)
*   o3-mini (green)
*   Claude-3.7 (red, lowest success rate for lower centrality, drops fastest)

## Slide 44: Breakpoint

### Breakpoint Performance

(Line graph with "Percentage correctly solved" on y-axis from 0% to 100%, and "Weighted tokens used" on x-axis (log scale) from 10,000 to 100,000.)

**Legend and Approximate Curves:**
*   OpenAI GPT-5 (dark blue, highest performance, reaches ~98% at 100,000 tokens)
*   Anthropic Opus 4 (purple, slightly below GPT-5, reaches ~95%)
*   OpenAI gpt-oss (light blue, significantly lower, reaches ~80%)
*   DeepSeek V3.1 (dark red, below gpt-oss, reaches ~78%)
*   DeepSeek R1-0528 (pink, even lower, reaches ~60%)
*   DeepSeek R1 (light pink, lowest performance, reaches ~25%)

NIST
CENTER FOR AI STANDARDS
AND INNOVATION (CAISI)

**Evaluation of DeepSeek AI Models**
Center for AI Standards and Innovation
National Institute of Standards and Technology

## Slide 45: What we learned

*   Most real world tasks requiring AI assistance require reasoning under uncertainty!
*   To figure out if we're making progress on these tasks, need evaluation benchmarks with questions that are intrinsically impossible to answer precisely, and evaluation metrics that treat uncertainty quantification as a first-class target.

## Slide 46: Thank you!

Belinda Li, Alex Tamkin, Kunal Handa, Gabe Grand, Valerio Pepe, Andi Peng, Alana Renda, Kaivu Hariharan, Uzay Girit, Atticus Wang

Yarin Gal, Noah Goodman, Ellie Pavlick, Josh Tenenbaum, Ilia Sucholutsky, Nishanth Kumar, Julie Shah, Andreea Bobu, Mike Cafarella

Thank you!

## Slide 47: (Image Credits/References)

Charles Bird King, Poor Artist's Cupboard, 1815
Anonymous, At the Writing Table, 1790
Daniel Huntington, Mercy's Dream, 1858
John Tercuzzi, Shop Sign Spectacles, 1935
Thomas Eakins, Baby at Play, 1876
Abraham Bloemaert, Shepherd pointing at Tobias and the Angel
Harry Hamilton Johnston, A Tuskegee Student
Nakamura Tekisai, Sōbo tōsho kinmō zui taisei, vols. 2-10
Temple Anshe Hesed, Cookbook of Temple's Tempting Tasties, 1930.
Charles West Cope, Mother Reading to a Child.
Vincent van Gogh, L'Arlésienne, 1888.
Keystone View Company, An Arithmetic Class, Tuskegee, Alabama, c. 1900.
Jean Simeon Chardin, The Little Schoolmistress, 1740.
Workshop of Philip Galle, Horologia Ferrea, 1590.