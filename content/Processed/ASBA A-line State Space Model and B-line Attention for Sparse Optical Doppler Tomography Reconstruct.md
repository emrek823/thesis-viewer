---
title: 'ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler
  Tomography Reconstruction'
authors:
- Zhenghong Li
- Wensheng Cheng
- Congwu Du
- Yingtian Pan
- Zhaozheng Yin
- Haibin Ling
date: '2026-01-20'
categories:
- cs.CV
pdf_url: https://arxiv.org/pdf/2601.14165v1
arxiv_id: 2601.14165v1
tags:
- paper
- alphaxiv/hot
- topic/cs-CV
---

# ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction

**Authors:** Zhenghong Li, Wensheng Cheng, Congwu Du, Yingtian Pan, Zhaozheng Yin...

**Date:** 2026-01-20 | **Categories:** cs.CV

[PDF](https://arxiv.org/pdf/2601.14165v1) | [AlphaXiv](https://alphaxiv.org/abs/2601.14165v1)

## Abstract

Optical Doppler Tomography (ODT) is an emerging blood flow analysis technique. A 2D ODT image (B-scan) is generated by sequentially acquiring 1D depth-resolved raw A-scans (A-line) along the lateral axis (B-line), followed by Doppler phase-subtraction analysis. To ensure high-fidelity B-scan images, current practices rely on dense sampling, which prolongs scanning time, increases storage demands, and limits the capture of rapid blood flow dynamics. Recent studies have explored sparse sampling of raw A-scans to alleviate these limitations, but their effectiveness is hindered by the conservative sampling rates and the uniform modeling of flow and background signals. In this study, we introduce a novel blood flow-aware network, named ASBA (A-line ROI State space model and B-line phase Attention), to reconstruct ODT images from highly sparsely sampled raw A-scans. Specifically, we propose an A-line ROI state space model to extract sparsely distributed flow features along the A-line, and a B-line phase attention to capture long-range flow signals along each B-line based on phase difference. Moreover, we introduce a flow-aware weighted loss function that encourages the network to prioritize the accurate reconstruction of flow signals. Extensive experiments on real animal data demonstrate that the proposed approach clearly outperforms existing state-of-the-art reconstruction methods.

## Notes

