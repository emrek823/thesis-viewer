---
url: https://bench.arise-ai.org/
title: "MAST Leaderboard"
clipped: 2026-01-02 22:51
source: browser-history
---

# MAST Leaderboard

> Source: [https://bench.arise-ai.org/](https://bench.arise-ai.org/)

### Best

Filter models▼

Confidence

Organization: AMBOSS

AMBOSS LiSA 1.0

62.3%CI: ± 0.5%

Organization: Google

Gemini 2.5 Pro

59.9%CI: ± 0.7%

Organization: Glass Health

Glass Health 4.0

59.0%CI: ± 1.2%

Organization: OpenAI

GPT-5

58.3%CI: ± 0.9%

Organization: Anthropic

Claude Sonnet 4.5

58.2%CI: ± 0.8%

### Selected

Organization: Human

Human Generalist Physicians

46.0%CI: ± 0.5%

### Worst

Organization: Alibaba

Qwen3 32B

48.8%CI: ± 1.0%

Organization: OpenAI

o4 mini

47.9%CI: ± 1.3%

Organization: OpenAI

o1 mini

47.5%CI: ± 1.4%

Organization: OpenAI

GPT-4o mini

43.7%CI: ± 1.2%

Organization: OpenAI

o3 mini

42.7%CI: ± 1.0%

Solo Models

Advisor

2-Agent Teams

Advisor + Guardian

3-Agent Teams

Advisor + Guardian + Guardian

About
:   NOHARM is a physician-validated medical benchmark to evaluate the accuracy and safety of AI-generated medical recommendations, grounded in real medical cases. The current version covers 10 specialties across 100 cases, and includes 12,747 specialist annotations on beneficial and harmful medical actions that can be taken in the 100 cases. This project is led and supported by the ARISE AI Research Network, based at Stanford and Harvard.

Motivation
:   As physicians, one of our core principles is to do no harm. With the rapid integration of AI technologies into medicine, how can we evaluate the harm of technologies? How do we evaluate how these models perform, compared to each other, and importantly, to ourselves?

Study
:   For details, see [our study](https://arxiv.org/abs/2512.01241).

Submissions
:   An automated submission portal is in the works. In the meanwhile, please contact us if you are interested benchmarking your model and inclusion in the leaderboard.

Contact
:   [Reach out to our team.](https://forms.gle/MD94gF5Ro8wo7N8y7)

## Study Authors

David Wu ([dwu@mgh.harvard.edu](mailto:dwu@mgh.harvard.edu)), Fateme Nateghi Haredasht, Saloni Kumar Maharaj, Priyank Jain, Jessica Tran, Matthew Gwiazdon, Arjun Rustagi, Jenelle Jindal, Jacob M. Koshy, Vinay Kadiyala, Anup Agarwal, Bassman Tappuni, Brianna French, Sirus Jesudasen, Christopher V. Cosgriff, Rebanta Chakraborty, Jillian Caldwell, Susan Ziolkowski, David J. Iberri, Robert Diep, Rahul S. Dalal, Kira L. Newman, Kristin Galetta, J. Carl Pallais, Nancy Wei, Kathleen M. Buchheit, David I. Hong, Ernest Y. Lee, Allen Shih, Vartan Pahalyants, Tamara B. Kaplan, Vishnu Ravi, Sarita Khemani, April S. Liang, Daniel Shirvani, Advait Patil, Nicholas Marshall, Kanav Chopra, Joel Koh, Adi Badhwar, Liam G. McCoy, David J. H. Wu, Yingjie Weng, Sumant Ranji, Kevin Schulman, Nigam H. Shah, Jason Hom, Arnold Milstein, Adam Rodman, Jonathan H. Chen, Ethan Goh