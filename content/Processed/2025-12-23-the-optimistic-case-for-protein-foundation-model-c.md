---
url: https://www.owlposting.com/p/the-optimistic-case-for-protein-foundation-193
title: "The optimistic case for protein foundation model companies"
clipped: 2025-12-23 13:01
source: slack
slack_channel: healthcare-aiml-deskresearch
---

# The optimistic case for protein foundation model companies

> Source: [https://www.owlposting.com/p/the-optimistic-case-for-protein-foundation-193](https://www.owlposting.com/p/the-optimistic-case-for-protein-foundation-193)

[Arguments](https://www.owlposting.com/s/arguments/?utm_source=substack&utm_medium=menu)

# The optimistic case for protein foundation model companies

### 2.4k words, 11 minute reading time

[![Abhishaike Mahajan's avatar](https://substackcdn.com/image/fetch/$s_!RQwq!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F983f59da-174d-48ac-b1cf-1d27464308ca_399x399.jpeg)](https://substack.com/@abhishaikemahajan)

[Abhishaike Mahajan](https://substack.com/@abhishaikemahajan)

Oct 11, 2025

∙ Paid

32

4

Share

[![](https://substackcdn.com/image/fetch/$s_!BczQ!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b401a16-5a6a-4ecc-8582-ec0b2afca7d2_2912x1632.png)](https://substackcdn.com/image/fetch/$s_!BczQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b401a16-5a6a-4ecc-8582-ec0b2afca7d2_2912x1632.png)

*Note: apologies for the double-send if you got two of these, I messed something up in the settings!*

1. [Introduction](https://www.owlposting.com/i/175891339/introduction)
2. [The optimistic arguments](https://www.owlposting.com/i/175891339/the-optimistic-arguments)

   1. [Multiproperty optimization](https://www.owlposting.com/i/175891339/multiproperty-optimization)
   2. [The value of infinite exploration](https://www.owlposting.com/i/175891339/the-value-of-infinite-exploration)
   3. [Open-source models will not be as common anymore if datasets grow more complex](https://www.owlposting.com/i/175891339/open-source-models-will-not-be-as-common-anymore-if-datasets-grow-more-complex)
   4. [Pharma prioritizes convenience more than you think](https://www.owlposting.com/i/175891339/pharma-prioritizes-convenience-more-than-you-think)

# Introduction

Let’s be honest with each other: the funding for protein foundation model startups got a little crazy for a moment. [EvolutionaryScale got $142M](https://fortune.com/2024/06/25/meta-ai-mafia-evolutionaryscale-llm-biology-seed-round-142-million/) in mid-2024, [Latent Labs got $50M](https://www.latentlabs.com/press-release/latent-labs-secures-50m-in-funding/) in early-2025, [Chai Discovery got $70M](https://www.businesswire.com/news/home/20250806670137/en/Chai-Discovery-Announces-%2470-million-Series-A-To-Transform-Molecular-Design) in mid-2025. And, of course, the giant two: [Isomorphic Labs with $600M](https://www.isomorphiclabs.com/articles/isomorphic-labs-announces-600m-external-investment-round) in funding in early 2025, and [Xaira Therapeutics with an insane $1B](https://www.fiercebiotech.com/biotech/new-ai-drug-discovery-powerhouse-xaira-rises-1b-funding) in funding in mid-2024.

Things have calmed down since then, so I think it’s a good moment to look back at this with some fresh eyes and ask: *was any of this a good idea?*

It’s become quite common to tell one another that no, obviously not, these were a series of escalating, FOMO-y investments that had basically zero basis in objective reality. I empathize with this viewpoint. Protein models are increasingly recognized as commoditized things, where the open-source stuff is actually quite good, and, even at the private level, there didn’t seem to be a strong differentiation between one group’s pretrained weights and another’s. If you really squinted, maybe, just maybe, the open-source [Boltz-1](https://www.biorxiv.org/content/10.1101/2024.11.19.624167v1) was slightly worse than Alphafold3 by a few percentage points in a few domains, but how much does that matter? Surely it’s all within a standard deviation of one another? How could this justify the immense investments needed to train these models?

But this view has also become so universally held that, honestly, it’s getting a little boring. Increasingly, I have grown more and more curious about what **actually** was the opinion of people who invested into these things. People knock on VC’s a lot, but I have a pretty high opinion of nearly every biotech VC I’ve met, and it’s difficult for me to imagine that it was all irrational. Unfortunately, the articles that VC’s write on why they invested into certain things — including these companies — are nearly always uninformative, mostly vague gesturing at ‘*the transformation of biology*’. You could look at this and think ‘*okay, nobody knows why they invested in this*’, but I mostly think the vagueness comes from the fact that they don’t have a strong financial incentive to say what their **actual** bet is.

So what was the actual reason to put money into these companies? It’s difficult to come up with a coherent narrative, so I’m just going to list a few interesting reasons that are swirling in my head.

# The optimistic arguments

## Multiproperty optimization

The divergence of private and public models being on par with one another may accelerate far faster than anyone thinks, entirely due to being able to afford the dataset necessary to optimize for multiple things at once.

Let’s consider [Chai-2’s results from July 2025](https://www.businesswire.com/news/home/20250630307418/en/Chai-Discovery-Unveils-Chai-2-Breakthrough-Achieving-Fully-De-Novo-Antibody-Design-With-AI) as a decent view into how much better the private models are than one open-sourced one—[RFDiffusion](https://www.nature.com/articles/s41586-023-06415-8)—for the task of miniprotein design. The results are hindered by a bit due to the fact that the **best** open-source miniprotein design model—[Bindcraft](https://www.nature.com/articles/s41586-025-09429-6)—is not included here. But whatever, let’s pretend RFDiffusion is as good as open-source gets.

[![](https://substackcdn.com/image/fetch/$s_!nxlg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F61a02f67-455c-44bb-8d4d-d5e1fabfa0a4_900x898.png)](https://substackcdn.com/image/fetch/$s_!nxlg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F61a02f67-455c-44bb-8d4d-d5e1fabfa0a4_900x898.png)

The usual argument at this point is ‘*who cares about a 10-20% → 80-100% bump?*’, given that these experiments can be run in 96-well plates? Yes, it saves money, but does it unlock dramatically new biology in a way that justifies having a brand new, very expensive model? Probably not!

But I think this is missing the forest for the trees a bit. Binder design is indeed not super interesting (anymore), but it’s worth thinking about what is beyond that. Because, in fact, it is very likely that the real value of these startups may have very little to do with their ability to create binders. Binding is literally just the **easiest** thing you can do, because the dataset to do it has already been mostly assembled: the PDB. So it’s a good place to start your modeling work. The far more interesting capabilities is in creating binders that **also** satisfy a bunch of useful biochemical properties.

What else is there? To name a few: expression, stability, solubility, immunogenicity, receptor promiscuity, manufacturability, and PK/PD. There are plenty of models for optimizing each of these properties one-at-a-time, but creating something that can jointly optimize all these at once is a taller order. A great recent blog post from the Oxford Protein Informatics group [discussed this a little, and you can see the inklings of open-sourced, multi-objective datasets here coming together, but it is still extremely early](https://www.blopig.com/blog/2025/07/antibody-developability-datasets/) and limited in size (almost always <1000 antibodies for non-binding datasets).

[![](https://substackcdn.com/image/fetch/$s_!1fF4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98c15875-90cc-43ff-a1c3-ecf6d7bff83f_902x1326.png)](https://substackcdn.com/image/fetch/$s_!1fF4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98c15875-90cc-43ff-a1c3-ecf6d7bff83f_902x1326.png)

What if there was a model that could really solve for all these things at once? What interesting things await if you can essentially automate a pretty significant fraction of the chemistry-relevant parts of the preclinical workflow? [The literature does imply it is quite significant:](https://www.contractpharma.com/characterizing-the-cost-of-non-clinical-development-activity/?utm_source=chatgpt.com)

> *Despite the substantial level of research spending and the growing reliance on outsourcing within the non-clinical domain, to our knowledge very little data exists on the economics of specific non-clinical activities and the comparative cost of internal vs. outsourced support. Andrews, Laurencot and Roy in 2006 reported that the direct cost to conduct specific non-clinical tests for a single compound ran from tens to hundreds of thousands of dollars.*
>
> *…Ferrandiz, Sussex and Towse in 2012 calculated that the average development costs from first toxicity dose to first human dose for a single compound was $6.5 million (2011$) with the costs ranging from **as low as $100,000 to as high as $27 million**.6 This wide range suggests many different variables affect the cost of non-clinical development.*

This is all perhaps an obvious point, but I think it is worthy of being explicitly called out. I have long felt that existing benchmarks in the biology-ML world have a tendency to ideologically capture people, limiting them to consider only the scope of what is currently measurable. Here, that is binding, but everything else is really important too! And it may be only the Big Players who can afford touching everything else.

## The value of infinite exploration

## Keep reading with a 7-day free trial

Subscribe to Owl Posting to keep reading this post and get 7 days of free access to the full post archives.

[Start trial](https://www.owlposting.com/subscribe?simple=true&next=https%3A%2F%2Fwww.owlposting.com%2Fp%2Fthe-optimistic-case-for-protein-foundation-193&utm_source=paywall-free-trial&utm_medium=web&utm_content=175891339&coupon=ef6f1c0f)

[Already a paid subscriber? **Sign in**](https://substack.com/sign-in?redirect=%2Fp%2Fthe-optimistic-case-for-protein-foundation-193&for_pub=abhishaike&change_user=false)