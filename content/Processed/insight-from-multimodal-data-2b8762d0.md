---
source_pdf: "https://drive.google.com/file/d/1fPlKyQgSZEc4Bxqn4mbQgbJ4LhMHQsrY/view?usp=drivesdk"
drive_folder: "Research"
type: research

ingested: 2025-12-26
original_filename: "Insight from Multimodal Data.pdf"
---

> **Original:** [View Original PDF](https://drive.google.com/file/d/1fPlKyQgSZEc4Bxqn4mbQgbJ4LhMHQsrY/view?usp=drivesdk)

# Deriving insights into drug discovery from multimodal data

## Why life science companies need to generate – and integrate – different dimensions of data

![QIAGEN Logo](No_OCR_but_visible_on_page_1)

![BIOPHARMA DIVE Logo](No_OCR_but_visible_on_page_1)

Custom content for QIAGEN by studioID

## Page 2

As biomarker discovery evolves, researchers are seeking more detail and deeper insights.

That's why more people are turning to multimodal data, where genomics and transcriptomics join proteomics, metabolomics and other data types for a comprehensive and composite biological view. With advanced tools for interpretation, integration and analysis, drug discovery researchers can apply multimodal data science in completely new ways.

A recent survey from QIAGEN Digital Insights and studioID adds color to these trends. In the survey, respondents cited genomics and transcriptomics (77%) as the data type they used most for data science-driven applications. But proteomics/ metabolomics (75%), chemical structure data (65%), preclinical in vivo data (62%) and preclinical in vitro data (59%) were trailing closely behind.

The survey indicates that while DNA and RNA still prevail, proteins, metabolites and other data types are growing in importance. When users can access this data seamlessly and reliably, extraordinary findings await.

### Top data types used for data science applications:*

| Data Type                      | Percentage |
| :----------------------------- | :--------- |
| Genomics/transcriptomics       | 77%        |
| Proteomics/metabolomics        | 75%        |
| Chemical structure data        | 65%        |
| Preclinical in vivo data       | 62%        |
| Preclinical in vitro data      | 59%        |

*Based on a BioPharma Dive survey among 150 biopharma executives, conducted in April 2025

## Page 3

> "Genomics and transcriptomics data gave us incredible insights into cellular behaviors. Now, we can look at which proteins are being transcribed and the kinds of metabolites they're synthesizing. This next level data can help the industry design better therapeutics. But as demand for metabolic data and proteomics data analysis increases, so does the need for high-throughput, advanced machine learning methods to derive insights. Although, it doesn't matter how great your ML is if you aren't starting with high-quality data."

Venkatesh Moktali, Ph.D., Director of Product Management
QIAGEN Digital Insights

We'll explore this shift toward multimodal data in biomarker discovery as validated by the studioID survey, including the trends contributing to this shift.

## Page 4: Going beyond DNA and RNA: How we got here

While the Human Genome Project revolutionized drug discovery research by mapping our genome, this is just the first piece of the puzzle. For more effective pharmaceutical products, researchers need to create a more detailed map than genomics alone can provide. This is where data like transcriptomics (RNA transcriptome), proteomics (proteins) and metabolomics (metabolites) can further improve our understanding of human biology.

While DNA can be thought of as the blueprint for an organism, it's a static library of information. It can't tell you anything about how these genes are expressed or the effects they have on a person's health. RNA transcripts can tell us about gene expression and cellular activity. These create proteins and other metabolites, which tell us what happens after these genes are transcribed. Researchers were eager to incorporate these data sources into their discovery programs.

"As with everything in this field, a combined view delivers a fuller, richer perspective than a siloed one, and that creates more informed biomarker discovery,” Moktali said. “That's why this interest in multimodal data has seen such increased demand – it adds important understanding to these genomic datasets, which previously had minimal context."

## Page 5

This increased interest is reflected in the markets around these data sources. Metabolomics is predicted to jump 17.5% in compound annual growth rate (CAGR) from 2024 to 2030,¹ followed by genomics (16.5%),² proteomics (12.9%)³ and transcriptomics (10.86%).⁴

Availability isn't the only factor contributing to this growth. Other outside forces have enabled and contributed to this shift toward multimodal inputs, such as mass spectrometry⁵ and, of course, artificial intelligence (AI).

Moktali highlighted the roles of emerging AI and machine learning (ML) techniques that can analyze extreme amounts of disparate data. Without that analytic power, researchers could only scrape the surface of what multimodal data can offer drug discovery programs.

"There's been a complete explosion in the number of people using these methods for different challenges and problems in the drug discovery workflow, from just extracting information to interpretation and building applications using the data," he said.

The powerful combination of big data with AI/ML has fueled an active precision medicine market that depends on these deeper insights. Investors, drawn in by the promise of success from these innovative pipelines, are further driving the field of multiomics.

Regulatory bodies are also supporting the use of multidimensional data. The Food and Drug Administration (FDA) has signaled its interest in using 'omics data in human health, such as holding an "Omics Days" symposium in 2024.⁶ And while much of the focus of the FDA's industry guidance tends to revolve around genomics, it has also noted that many of the frameworks established are also applicable to nongenomic biomarkers.⁷

## Page 6: Overcoming the challenges of multimodal data

Multimodal data, by its nature, comes from diverse sources. It can be incredibly powerful once combined, but actually combining those sources is easier said than done. Bioinformatics data is dispersed across different sources with varying ontologies, formats, standards and definitions. You can't compare apples to oranges. Integrating internal data with "free" and publicly sourced data highlights these challenges, Moktali said.

“Bioinformatics data is quite plentiful in this industry. You may recognize collections like the Cancer Genomic Atlas Program (TCGA), the Gene Expression Omnibus (GEO) and the Genotype-Tissue Expression (GTEx),” he said. "While the availability of that data may sound like an advantage – and it certainly is – it's not without its complications when it comes to combining one dataset that conforms to one ontology with another."

Moktali added that, in his experience, every dataset needs processing to prepare it for analysis. Datasets are often fraught with minor errors and gaps that can slow down this process. Corrections and additions are largely manual, which can compromise timelines and consume resources, he added, noting the 80/20 rule of data science.⁸

### Data challenges based on QIAGEN Digital Insights internal data:

| Challenge                                                        | Percentage |
| :--------------------------------------------------------------- | :--------- |
| of datasets require manual effort to ensure consistency          | 100%       |
| have typos and minor errors                                      | 35%        |
| require author feedback to address inconsistent terms, mislabeling or other errors | 5-10%      |

Source: QIAGEN Digital Insights, based on internal data

## Page 7

"After you get access to this huge amount of data, your problems are just beginning. You're going to spend 80% of your time just making that data accessible," Moktali said. "All this data engineering diverts valuable time and energy from actual discovery, which ends up as almost an afterthought."

On average, each dataset requires 16 person-hours to make it accessible, according to QIAGEN Digital Insights experts.

And that's just the initial investment. Databases are updated regularly, so additional effort may be required as 'omics collections evolve.

"When you're too busy cleaning, processing, standardizing and removing errors, it can make it more challenging to derive meaningful insights,” Moktali said. "And isn't that the whole point?"

Every dataset costs an average of 16 person-hours to prepare for analysis.

### How much time is spent readying data?

| Task                          | Percentage |
| :---------------------------- | :--------- |
| Cleaning and organizing data  | 60%        |
| Collecting datasets           | 19%        |
| Mining data for patterns      | 9%         |
| Refining algorithms           | 4%         |
| Building training sets        | 3%         |
| Other                         | 5%         |

Source: H. Sarih, A. P. Tchangani, K. Medjaher and E. Pere, "Data preparation and preprocessing for broadcast systems monitoring in PHM framework," 2019 6th International Conference on Control, Decision and Information Technologies (CoDIT), Paris, France, 2019, pp. 1444-1449, doi: 10.1109/CoDIT.2019.8820370.

## Page 8: Why curated, high-quality data matters

As organizations dive deeper into the world of 'omics databases, many teams can understandably become overwhelmed with the effort needed to make the data actionable. This may require additional resources and expertise, both of which take time and money to acquire.

That's why many teams are moving away from free 'omics repositories toward data curation services. Combining machine-enabled and human-led efforts, QIAGEN Digital Insights data curation creates a single, standardized ontology and framework, supported by metadata identifiers, that includes public and private datasets. With metadata-powered searches, users can easily find and retrieve data without worrying about including every possible synonym in their search.

“With metadata and a unified ontology, we create a sort of baseline language that every 'omics data point can speak, so even if the terms aren't identical, they're recognized as synonyms," Moktali said. "This requires a lot of work and expertise on our end, but from the customer's perspective, it's just a few mouse clicks. Teams are freed from any manual curation efforts, and they can find useful datasets they wouldn't have found through traditional filters. This way, teams can focus on what matters: deriving insights."

## Page 9

On top of these benefits, Moktali added, human curation helps protect against AI hallucinations – an inescapable byproduct of any generative AI tool. Despite their power, they've been found to give inaccurate answers up to fifty percent of the time, or more.⁹

"We're seeing organizations rely more on AI technologies to help quickly analyze and query 'omics data," he said. "But while these high-powered tools can facilitate that analysis at scale, they're not always reliable. They hallucinate. And without curator review, there's no safeguard in place to prevent that from happening. So humans, ideally, should always be kept in the loop."

## Page 10: Get more from multimodal data

As drug discovery programs mature, we're also improving the underlying data that informs them. Genomics and transcriptomics include essential insights into our DNA and RNA, but integrating those datasets with metabolomics, proteomics and other 'omics data paints a fuller, more dimensional picture of functional biology.

More data brings more work, and not every team has the time, resources or inclination to navigate inconsistent ontologies, correct errors and verify information with primary sources. Human-led, machine-enabled curation is the answer, helping organizations derive insights without delay.

Learn more at [www.digitalinsights.qiagen.com/bkb](http://www.digitalinsights.qiagen.com/bkb)

## Page 11: References

1.  [https://www.grandviewresearch.com/horizon/statistics/multiomics-market/platform/metabolomics/global](https://www.grandviewresearch.com/horizon/statistics/multiomics-market/platform/metabolomics/global)
2.  [https://www.grandviewresearch.com/industry-analysis/genomics-market](https://www.grandviewresearch.com/industry-analysis/genomics-market)
3.  [https://www.grandviewresearch.com/industry-analysis/proteomics-market](https://www.grandviewresearch.com/industry-analysis/proteomics-market)
4.  [https://www.grandviewresearch.com/industry-analysis/transcriptomics-technologies-market](https://www.grandviewresearch.com/industry-analysis/transcriptomics-technologies-market)
5.  [https://www.sciencedirect.com/science/article/pii/S2211383523001661](https://www.sciencedirect.com/science/article/pii/S2211383523001661)
6.  [https://www.fda.gov/science-research/scientific-meetings-conferences-and-workshops/fda-omics-days-2024-precision-practice-regulatory-science-best-practices-and-future-directions-omics](https://www.fda.gov/science-research/scientific-meetings-conferences-and-workshops/fda-omics-days-2024-precision-practice-regulatory-science-best-practices-and-future-directions-omics)
7.  [https://www.fda.gov/media/81311/download](https://www.fda.gov/media/81311/download)
8.  [https://www.pragmaticinstitute.com/resources/articles/data/overcoming-the-80-20-rule-in-data-science/](https://www.pragmaticinstitute.com/resources/articles/data/overcoming-the-80-20-rule-in-data-science/)
9.  [https://www.forbes.com/sites/conormurray/2025/05/06/why-ai-hallucinations-are-worse-than-ever/](https://www.forbes.com/sites/conormurray/2025/05/06/why-ai-hallucinations-are-worse-than-ever/)

## Page 12

### About QIAGEN Digital Insights

QIAGEN Digital Insights is the leading provider of genomic and clinical knowledge, analysis and interpretation software and services for scientists and clinicians. With over 25 years of experience in bioinformatics, 140,000 users worldwide, 100,000 citations in scientific papers and 5 million profiled patient cases, our quality knowledge and software will help you gain insights into everything from early discovery to clinical decision-making. Discover our curated knowledge solutions, bioinformatics software and services for better data management, collaboration and actionable insights.

### About QIAGEN

QIAGEN N.V., a Netherlands-based holding company, is the leading global provider of Sample to Insight solutions that enable customers to gain valuable molecular insights from samples containing the building blocks of life. Our sample technologies isolate and process DNA, RNA and proteins from blood, tissue and other materials. Assay technologies make these biomolecules visible and ready for analysis. Bioinformatics software and knowledge bases interpret data to report relevant, actionable insights. Automation solutions tie these together in seamless and cost-effective workflows. QIAGEN provides solutions to more than 500,000 customers around the world in Molecular Diagnostics (human health care) and Life Sciences (academia, pharma R&D and industrial applications, primarily forensics). As of Dec. 31, 2023, QIAGEN employed about 6,000 people in over 35 locations worldwide.

Learn more and request more information at [www.digitalinsights.qiagen.com/bkb](http://www.digitalinsights.qiagen.com/bkb)

Ordering [www.qiagen.com/shop](http://www.qiagen.com/shop) | Technical Support [www.support.qiagen.com](http://www.support.qiagen.com) | Website [www.qiagen.com](http://www.qiagen.com)

## Page 13

# studio/ID

BY INDUSTRY DIVE

studioID is Industry Dive's global content studio offering brands an ROI rich tool kit: Deep industry expertise, first-party audience insights, an editorial approach to brand storytelling, and targeted distribution capabilities. Our trusted in-house content marketers help brands power insights-fueled content programs that nurture prospects and customers from discovery through to purchase, connecting brand to demand.

Learn more